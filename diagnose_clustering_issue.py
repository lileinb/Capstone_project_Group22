#!/usr/bin/env python3
"""
è¯Šæ–­èšç±»é—®é¢˜ - æ¨¡æ‹Ÿå‰ç«¯çœŸå®æ•°æ®
"""

import pandas as pd
import numpy as np
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from backend.clustering.cluster_analyzer import ClusterAnalyzer
from backend.feature_engineer.risk_features import RiskFeatureEngineer

def load_real_data():
    """åŠ è½½çœŸå®çš„CSVæ•°æ®ï¼ˆæ¨¡æ‹Ÿå‰ç«¯åŠ è½½çš„æ•°æ®ï¼‰"""
    try:
        # å°è¯•åŠ è½½çœŸå®æ•°æ®
        data_path = "data/fraud_detection_dataset.csv"
        if os.path.exists(data_path):
            df = pd.read_csv(data_path)
            print(f"âœ… åŠ è½½çœŸå®æ•°æ®: {df.shape}")
            return df
        else:
            print("âš ï¸ çœŸå®æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return create_realistic_data()
    except Exception as e:
        print(f"âš ï¸ åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
        return create_realistic_data()

def create_realistic_data():
    """åˆ›å»ºæ›´çœŸå®çš„æ•°æ®ï¼ˆæ¨¡æ‹Ÿå‰ç«¯å¯èƒ½é‡åˆ°çš„æ•°æ®ï¼‰"""
    np.random.seed(42)
    n_samples = 1000
    
    # åˆ›å»ºåŸºç¡€æ•°æ®
    data = {
        'transaction_amount': np.random.lognormal(4, 1.2, n_samples),
        'customer_age': np.random.normal(40, 15, n_samples),
        'account_age_days': np.random.exponential(365, n_samples),
        'transaction_hour': np.random.randint(0, 24, n_samples),
        'quantity': np.random.poisson(2, n_samples) + 1,
        'payment_method': np.random.choice(['credit card', 'debit card', 'bank transfer'], n_samples),
        'product_category': np.random.choice(['electronics', 'clothing', 'home'], n_samples),
        'device_used': np.random.choice(['desktop', 'mobile', 'tablet'], n_samples),
        'shipping_address': np.random.choice(['same', 'different'], n_samples, p=[0.8, 0.2]),
        'billing_address': np.random.choice(['same', 'different'], n_samples, p=[0.9, 0.1]),
        'is_fraudulent': np.random.choice([0, 1], n_samples, p=[0.95, 0.05])
    }
    
    return pd.DataFrame(data)

def diagnose_clustering_pipeline():
    """è¯Šæ–­å®Œæ•´çš„èšç±»æµç¨‹"""
    print("ğŸ” å¼€å§‹è¯Šæ–­èšç±»æµç¨‹")
    
    # 1. åŠ è½½æ•°æ®
    print("\nğŸ“Š æ­¥éª¤1: åŠ è½½æ•°æ®")
    raw_data = load_real_data()
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {raw_data.shape}")
    print(f"åŸå§‹ç‰¹å¾: {list(raw_data.columns)}")
    
    # 2. ç‰¹å¾å·¥ç¨‹ï¼ˆæ¨¡æ‹Ÿå‰ç«¯çš„ç‰¹å¾å·¥ç¨‹ï¼‰
    print("\nğŸ”§ æ­¥éª¤2: ç‰¹å¾å·¥ç¨‹")
    try:
        risk_engineer = RiskFeatureEngineer()
        engineered_data = risk_engineer.engineer_risk_features(raw_data)
        print(f"å·¥ç¨‹åŒ–æ•°æ®å½¢çŠ¶: {engineered_data.shape}")
        print(f"æ–°å¢ç‰¹å¾æ•°: {len(engineered_data.columns) - len(raw_data.columns)}")
        print(f"å·¥ç¨‹åŒ–ç‰¹å¾ç¤ºä¾‹: {list(engineered_data.columns)[:10]}...")
    except Exception as e:
        print(f"âŒ ç‰¹å¾å·¥ç¨‹å¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…: {e}")
        engineered_data = raw_data
    
    # 3. æ™ºèƒ½èšç±»
    print("\nğŸ¤– æ­¥éª¤3: æ™ºèƒ½èšç±»")
    cluster_analyzer = ClusterAnalyzer()
    
    try:
        intelligent_result = cluster_analyzer.intelligent_auto_clustering(engineered_data)
        
        if intelligent_result:
            print("âœ… æ™ºèƒ½èšç±»æˆåŠŸ")
            print(f"   ç®—æ³•: {intelligent_result.get('algorithm', 'unknown')}")
            print(f"   èšç±»æ•°: {intelligent_result.get('n_clusters', 0)}")
            print(f"   è½®å»“ç³»æ•°: {intelligent_result.get('silhouette_score', 0):.3f}")
            print(f"   é€‰æ‹©ç‰¹å¾æ•°: {len(intelligent_result.get('selected_features', []))}")
            
            # æ£€æŸ¥è½®å»“ç³»æ•°æ˜¯å¦å¼‚å¸¸
            silhouette = intelligent_result.get('silhouette_score', 0)
            if silhouette > 0.8:
                print("âš ï¸ è­¦å‘Š: è½®å»“ç³»æ•°å¼‚å¸¸é«˜ï¼Œå¯èƒ½å­˜åœ¨è®¡ç®—é”™è¯¯")
            elif silhouette < 0.2:
                print("âš ï¸ è­¦å‘Š: è½®å»“ç³»æ•°è¾ƒä½ï¼Œèšç±»æ•ˆæœä¸ä½³")
            else:
                print("âœ… è½®å»“ç³»æ•°åœ¨åˆç†èŒƒå›´å†…")
                
        else:
            print("âŒ æ™ºèƒ½èšç±»å¤±è´¥")
            intelligent_result = {}
            
    except Exception as e:
        print(f"âŒ æ™ºèƒ½èšç±»å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        intelligent_result = {}
    
    # 4. æ‰‹åŠ¨èšç±»å¯¹æ¯”
    print("\nğŸ”§ æ­¥éª¤4: æ‰‹åŠ¨èšç±»å¯¹æ¯”")
    try:
        manual_result = cluster_analyzer.analyze_clusters(engineered_data, algorithm='auto')
        
        if manual_result:
            manual_silhouette = manual_result.get('quality_metrics', {}).get('silhouette_score', 0)
            print("âœ… æ‰‹åŠ¨èšç±»æˆåŠŸ")
            print(f"   ç®—æ³•: {manual_result.get('algorithm', 'unknown')}")
            print(f"   èšç±»æ•°: {manual_result.get('cluster_count', 0)}")
            print(f"   è½®å»“ç³»æ•°: {manual_silhouette:.3f}")
        else:
            print("âŒ æ‰‹åŠ¨èšç±»å¤±è´¥")
            manual_result = {}
            
    except Exception as e:
        print(f"âŒ æ‰‹åŠ¨èšç±»å¼‚å¸¸: {e}")
        manual_result = {}
    
    # 5. å¯¹æ¯”åˆ†æ
    print("\nğŸ“Š æ­¥éª¤5: å¯¹æ¯”åˆ†æ")
    intelligent_silhouette = intelligent_result.get('silhouette_score', 0)
    manual_silhouette = manual_result.get('quality_metrics', {}).get('silhouette_score', 0)
    
    print(f"æ™ºèƒ½èšç±»è½®å»“ç³»æ•°: {intelligent_silhouette:.3f}")
    print(f"æ‰‹åŠ¨èšç±»è½®å»“ç³»æ•°: {manual_silhouette:.3f}")
    
    if intelligent_silhouette > manual_silhouette:
        improvement = ((intelligent_silhouette - manual_silhouette) / manual_silhouette) * 100 if manual_silhouette > 0 else 0
        print(f"âœ… æ™ºèƒ½èšç±»æ›´å¥½ï¼Œæå‡ {improvement:.1f}%")
    elif manual_silhouette > intelligent_silhouette:
        degradation = ((manual_silhouette - intelligent_silhouette) / manual_silhouette) * 100 if manual_silhouette > 0 else 0
        print(f"âŒ æ™ºèƒ½èšç±»è¾ƒå·®ï¼Œä¸‹é™ {degradation:.1f}%")
    else:
        print("âš–ï¸ ä¸¤ç§æ–¹æ³•æ•ˆæœç›¸å½“")
    
    # 6. é—®é¢˜è¯Šæ–­
    print("\nğŸ” æ­¥éª¤6: é—®é¢˜è¯Šæ–­")
    issues = []
    
    if intelligent_silhouette > 0.9:
        issues.append("æ™ºèƒ½èšç±»è½®å»“ç³»æ•°å¼‚å¸¸é«˜ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆæˆ–è®¡ç®—é”™è¯¯")
    
    if intelligent_silhouette < 0.2:
        issues.append("æ™ºèƒ½èšç±»è½®å»“ç³»æ•°è¿‡ä½ï¼Œç‰¹å¾é€‰æ‹©æˆ–ç®—æ³•é€‰æ‹©å¯èƒ½æœ‰é—®é¢˜")
    
    if abs(intelligent_silhouette - manual_silhouette) > 0.3:
        issues.append("æ™ºèƒ½èšç±»ä¸æ‰‹åŠ¨èšç±»å·®å¼‚è¿‡å¤§ï¼Œå¯èƒ½å­˜åœ¨å®ç°ä¸ä¸€è‡´")
    
    if len(intelligent_result.get('selected_features', [])) > 15:
        issues.append("é€‰æ‹©çš„ç‰¹å¾æ•°é‡è¿‡å¤šï¼Œå¯èƒ½å¯¼è‡´ç»´åº¦ç¾éš¾")
    
    if len(intelligent_result.get('selected_features', [])) < 3:
        issues.append("é€‰æ‹©çš„ç‰¹å¾æ•°é‡è¿‡å°‘ï¼Œå¯èƒ½ä¿¡æ¯ä¸è¶³")
    
    if issues:
        print("âš ï¸ å‘ç°çš„é—®é¢˜:")
        for i, issue in enumerate(issues, 1):
            print(f"   {i}. {issue}")
    else:
        print("âœ… æœªå‘ç°æ˜æ˜¾é—®é¢˜")
    
    # 7. å»ºè®®
    print("\nğŸ’¡ æ­¥éª¤7: ä¼˜åŒ–å»ºè®®")
    if intelligent_silhouette < 0.3:
        print("å»ºè®®:")
        print("   1. æ£€æŸ¥ç‰¹å¾å·¥ç¨‹è´¨é‡")
        print("   2. è°ƒæ•´ç‰¹å¾é€‰æ‹©ç­–ç•¥")
        print("   3. ä¼˜åŒ–èšç±»ç®—æ³•å‚æ•°")
        print("   4. å¢åŠ æ•°æ®é¢„å¤„ç†æ­¥éª¤")
    elif intelligent_silhouette > 0.8:
        print("å»ºè®®:")
        print("   1. æ£€æŸ¥è½®å»“ç³»æ•°è®¡ç®—æ˜¯å¦æ­£ç¡®")
        print("   2. éªŒè¯èšç±»ç»“æœçš„ä¸šåŠ¡æ„ä¹‰")
        print("   3. æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ•°æ®æ³„éœ²")
    else:
        print("âœ… èšç±»æ•ˆæœè‰¯å¥½ï¼Œæ— éœ€ç‰¹åˆ«ä¼˜åŒ–")
    
    return {
        'intelligent_result': intelligent_result,
        'manual_result': manual_result,
        'data_shape': engineered_data.shape,
        'issues': issues
    }

if __name__ == "__main__":
    results = diagnose_clustering_pipeline()
    
    print(f"\nğŸ¯ è¯Šæ–­å®Œæˆ")
    print(f"æ•°æ®è§„æ¨¡: {results['data_shape']}")
    print(f"å‘ç°é—®é¢˜æ•°: {len(results['issues'])}")
    
    if results['issues']:
        print("éœ€è¦é‡ç‚¹å…³æ³¨çš„é—®é¢˜:")
        for issue in results['issues']:
            print(f"  - {issue}")
