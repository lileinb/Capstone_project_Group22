"""
Analysis Report Page
Responsible for generating comprehensive analysis reports and explainability analysis
"""

import streamlit as st
import pandas as pd
import numpy as np
import sys
import os
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# å¯¼å…¥åç«¯æ¨¡å—
from backend.explainer.shap_explainer import SHAPExplainer
from backend.explainer.lime_explainer import LIMEExplainer
from backend.analysis_reporting.report_generator import ReportGenerator

def show():
    """Display analysis report page"""
    st.markdown('<div class="sub-header">ğŸ“‹ Comprehensive Analysis Report & Explainability Analysis</div>', unsafe_allow_html=True)

    # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å¾å·¥ç¨‹æ•°æ®
    if 'engineered_features' not in st.session_state or st.session_state.engineered_features is None:
        st.warning("âš ï¸ Please complete feature engineering first!")
        st.info("ğŸ’¡ Please complete feature generation on the 'ğŸ”§ Feature Engineering' page")
        return
    
    # åˆå§‹åŒ–session state
    if 'shap_analysis' not in st.session_state:
        st.session_state.shap_analysis = None
    if 'lime_analysis' not in st.session_state:
        st.session_state.lime_analysis = None
    if 'report_data' not in st.session_state:
        st.session_state.report_data = None
    
    # è·å–ç‰¹å¾å·¥ç¨‹æ•°æ®
    engineered_data = st.session_state.engineered_features
    
    st.markdown("### ğŸ“Š Data Overview")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Records", f"{len(engineered_data):,}")
    
    with col2:
        st.metric("Feature Count", f"{len(engineered_data.columns)}")

    with col3:
        numeric_features = len(engineered_data.select_dtypes(include=['number']).columns)
        st.metric("Numeric Features", f"{numeric_features}")

    with col4:
        if 'is_fraudulent' in engineered_data.columns:
            fraud_rate = (engineered_data['is_fraudulent'].sum() / len(engineered_data) * 100).round(2)
            st.metric("Fraud Rate", f"{fraud_rate}%")
        else:
            st.metric("Fraud Rate", "N/A")

    # æŠ¥å‘Šé…ç½®
    st.markdown("### âš™ï¸ Report Configuration")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ğŸ“‹ Report Content Selection")

        # æŠ¥å‘Šå†…å®¹é€‰æ‹©
        include_data_analysis = st.checkbox("Data Analysis Report", value=True)
        include_model_performance = st.checkbox("Model Performance Report", value=True)
        include_risk_assessment = st.checkbox("Risk Assessment Report", value=True)
        include_attack_analysis = st.checkbox("Attack Analysis Report", value=True)
        include_explainability = st.checkbox("Explainability Analysis", value=True)
        include_recommendations = st.checkbox("Protection Recommendations", value=True)

    with col2:
        st.markdown("#### ğŸ¯ Explainability Analysis")

        # å¯è§£é‡Šæ€§åˆ†æé€‰æ‹©
        include_shap_analysis = st.checkbox("SHAP Analysis", value=True)
        include_lime_analysis = st.checkbox("LIME Analysis", value=True)

        # åˆ†ææ ·æœ¬æ•°
        analysis_sample_size = st.slider(
            "Analysis Sample Size", 100, 1000, 500,
            help="Number of samples for explainability analysis"
        )

        # ç‰¹å¾é‡è¦æ€§é˜ˆå€¼
        feature_importance_threshold = st.slider(
            "Feature Importance Threshold", 0.01, 0.1, 0.05, 0.01,
            help="Minimum threshold for displaying feature importance"
        )
    
    # æŠ¥å‘Šæ ¼å¼é€‰æ‹©
    st.markdown("#### ğŸ“„ Report Format")

    col1, col2, col3 = st.columns(3)

    with col1:
        export_pdf = st.checkbox("PDF Format", value=True)

    with col2:
        export_excel = st.checkbox("Excel Format", value=True)

    with col3:
        export_html = st.checkbox("HTML Format", value=True)

    # æ‰§è¡Œåˆ†æ
    if st.button("ğŸš€ Generate Analysis Report", type="primary", help="Generate comprehensive analysis report based on current configuration"):
        try:
            with st.spinner("Generating analysis report..."):
                # å‡†å¤‡æ•°æ®
                X = engineered_data.select_dtypes(include=['number'])
                if 'is_fraudulent' in X.columns:
                    y = X['is_fraudulent']
                    X = X.drop('is_fraudulent', axis=1)
                    has_labels = True
                else:
                    y = None
                    has_labels = False

                # å¤„ç†ç¼ºå¤±å€¼
                X = X.fillna(0)

                # SHAPåˆ†æ
                if include_shap_analysis and has_labels:
                    try:
                        shap_explainer = SHAPExplainer()
                        shap_analysis = shap_explainer.analyze(X, y, sample_size=analysis_sample_size)
                        st.session_state.shap_analysis = shap_analysis
                        st.success("âœ… SHAP analysis completed")
                    except Exception as e:
                        st.warning(f"âš ï¸ SHAP analysis failed: {e}")

                # LIMEåˆ†æ
                if include_lime_analysis and has_labels:
                    try:
                        lime_explainer = LIMEExplainer()
                        lime_analysis = lime_explainer.analyze(X, y, sample_size=analysis_sample_size)
                        st.session_state.lime_analysis = lime_analysis
                        st.success("âœ… LIME analysis completed")
                    except Exception as e:
                        st.warning(f"âš ï¸ LIME analysis failed: {e}")
                
                # ç”ŸæˆæŠ¥å‘Šæ•°æ®
                report_data = {
                    'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    'total_samples': len(engineered_data),
                    'fraud_samples': int(engineered_data['is_fraudulent'].sum()) if 'is_fraudulent' in engineered_data.columns else 0,
                    'fraud_rate': fraud_rate if 'is_fraudulent' in engineered_data.columns else 0,
                    'data_info': {
                        'total_records': len(engineered_data),
                        'total_features': len(engineered_data.columns),
                        'numeric_features': len(engineered_data.select_dtypes(include=['number']).columns),
                        'fraud_rate': fraud_rate if 'is_fraudulent' in engineered_data.columns else None
                    },
                    'analysis_config': {
                        'include_data_analysis': include_data_analysis,
                        'include_model_performance': include_model_performance,
                        'include_risk_assessment': include_risk_assessment,
                        'include_attack_analysis': include_attack_analysis,
                        'include_explainability': include_explainability,
                        'include_recommendations': include_recommendations,
                        'include_shap_analysis': include_shap_analysis,
                        'include_lime_analysis': include_lime_analysis,
                        'analysis_sample_size': analysis_sample_size,
                        'feature_importance_threshold': feature_importance_threshold
                    },
                    'export_formats': {
                        'pdf': export_pdf,
                        'excel': export_excel,
                        'html': export_html
                    }
                }
                
                # æ·»åŠ å…¶ä»–åˆ†æç»“æœ
                if 'clustering_results' in st.session_state:
                    report_data['clustering_results'] = st.session_state.clustering_results
                
                if 'risk_scores' in st.session_state:
                    report_data['risk_analysis'] = st.session_state.risk_analysis
                
                if 'model_predictions' in st.session_state:
                    report_data['model_performance'] = st.session_state.model_performance
                
                if 'attack_results' in st.session_state:
                    report_data['attack_analysis'] = st.session_state.attack_analysis
                
                st.session_state.report_data = report_data
                
                st.success("âœ… åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
                
        except Exception as e:
            st.error(f"âŒ åˆ†ææŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
            st.exception(e)
    
    # æ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.report_data is not None:
        st.markdown("### ğŸ“ˆ åˆ†æç»“æœ")
        
        report_data = st.session_state.report_data
        
        # æŠ¥å‘Šæ¦‚è§ˆ
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("åˆ†ææ—¶é—´", report_data['timestamp'])
        
        with col2:
            st.metric("è®°å½•æ•°", f"{report_data['data_info']['total_records']:,}")
        
        with col3:
            st.metric("ç‰¹å¾æ•°", report_data['data_info']['total_features'])
        
        with col4:
            if report_data['data_info']['fraud_rate'] is not None:
                st.metric("æ¬ºè¯ˆç‡", f"{report_data['data_info']['fraud_rate']}%")
            else:
                st.metric("æ¬ºè¯ˆç‡", "N/A")
        
        # SHAPåˆ†æç»“æœ
        if st.session_state.shap_analysis is not None:
            st.markdown("#### ğŸ¯ SHAPå¯è§£é‡Šæ€§åˆ†æ")
            
            shap_analysis = st.session_state.shap_analysis
            
            # ç‰¹å¾é‡è¦æ€§
            if 'feature_importance' in shap_analysis:
                importance_df = pd.DataFrame(shap_analysis['feature_importance'])
                importance_df = importance_df.sort_values('importance', ascending=False)
                
                # æ˜¾ç¤ºå‰10ä¸ªé‡è¦ç‰¹å¾
                top_features = importance_df.head(10)
                
                fig = px.bar(
                    top_features,
                    x='feature',
                    y='importance',
                    title="SHAPç‰¹å¾é‡è¦æ€§æ’åº",
                    labels={'feature': 'ç‰¹å¾', 'importance': 'é‡è¦æ€§'}
                )
                st.plotly_chart(fig, use_container_width=True)
                
                # ç‰¹å¾é‡è¦æ€§è¡¨æ ¼
                st.dataframe(top_features, use_container_width=True)
            
            # ç‰¹å¾è´¡çŒ®åˆ†æ
            if 'feature_contributions' in shap_analysis:
                st.markdown("**ç‰¹å¾è´¡çŒ®åˆ†æ**")
                
                # é€‰æ‹©è¦åˆ†æçš„æ ·æœ¬
                if len(shap_analysis['feature_contributions']) > 0:
                    sample_index = st.selectbox(
                        "é€‰æ‹©æ ·æœ¬æŸ¥çœ‹SHAPè´¡çŒ®",
                        range(len(shap_analysis['feature_contributions'])),
                        format_func=lambda x: f"æ ·æœ¬ {x+1}"
                    )
                    
                    if 0 <= sample_index < len(shap_analysis['feature_contributions']):
                        sample_contributions = shap_analysis['feature_contributions'][sample_index]
                        
                        # åˆ›å»ºç€‘å¸ƒå›¾
                        contrib_df = pd.DataFrame(sample_contributions)
                        contrib_df = contrib_df.sort_values('contribution', ascending=False)
                        
                        fig = px.bar(
                            contrib_df,
                            x='feature',
                            y='contribution',
                            title=f"æ ·æœ¬ {sample_index+1} SHAPç‰¹å¾è´¡çŒ®",
                            labels={'feature': 'ç‰¹å¾', 'contribution': 'è´¡çŒ®å€¼'},
                            color='contribution',
                            color_continuous_scale='RdBu'
                        )
                        st.plotly_chart(fig, use_container_width=True)
        
        # LIMEåˆ†æç»“æœ
        if st.session_state.lime_analysis is not None:
            st.markdown("#### ğŸ” LIMEå±€éƒ¨è§£é‡Šåˆ†æ")
            
            lime_analysis = st.session_state.lime_analysis
            
            # å±€éƒ¨è§£é‡Š
            if 'local_explanations' in lime_analysis:
                st.markdown("**å±€éƒ¨è§£é‡Šåˆ†æ**")
                
                # é€‰æ‹©è¦åˆ†æçš„æ ·æœ¬
                if len(lime_analysis['local_explanations']) > 0:
                    lime_sample_index = st.selectbox(
                        "é€‰æ‹©æ ·æœ¬æŸ¥çœ‹LIMEè§£é‡Š",
                        range(len(lime_analysis['local_explanations'])),
                        format_func=lambda x: f"æ ·æœ¬ {x+1}"
                    )
                    
                    if 0 <= lime_sample_index < len(lime_analysis['local_explanations']):
                        local_explanation = lime_analysis['local_explanations'][lime_sample_index]
                        
                        # æ˜¾ç¤ºå±€éƒ¨è§£é‡Š
                        st.markdown(f"**æ ·æœ¬ {lime_sample_index+1} çš„LIMEè§£é‡Š**")
                        
                        if 'feature_weights' in local_explanation:
                            weights_df = pd.DataFrame(local_explanation['feature_weights'])
                            weights_df = weights_df.sort_values('weight', ascending=False)
                            
                            fig = px.bar(
                                weights_df,
                                x='feature',
                                y='weight',
                                title=f"æ ·æœ¬ {lime_sample_index+1} LIMEç‰¹å¾æƒé‡",
                                labels={'feature': 'ç‰¹å¾', 'weight': 'æƒé‡'},
                                color='weight',
                                color_continuous_scale='RdBu'
                            )
                            st.plotly_chart(fig, use_container_width=True)
        
        # ç»¼åˆåˆ†æ
        st.markdown("#### ğŸ“Š ç»¼åˆåˆ†æ")
        
        # åˆ›å»ºç»¼åˆåˆ†æå›¾è¡¨
        analysis_summary = []
        
        # æ•°æ®è´¨é‡åˆ†æ
        if 'data_info' in report_data:
            data_info = report_data['data_info']
            analysis_summary.append({
                'åˆ†æé¡¹ç›®': 'æ•°æ®è´¨é‡',
                'è®°å½•æ•°': data_info['total_records'],
                'ç‰¹å¾æ•°': data_info['total_features'],
                'æ•°å€¼ç‰¹å¾': data_info['numeric_features'],
                'æ¬ºè¯ˆç‡': data_info['fraud_rate']
            })
        
        # èšç±»åˆ†æ
        if 'clustering_results' in report_data:
            clustering_results = report_data['clustering_results']
            analysis_summary.append({
                'Analysis Item': 'Clustering Analysis',
                'Algorithm': clustering_results.get('algorithm', 'N/A'),
                'Cluster Count': clustering_results.get('n_clusters', 'N/A'),
                'Feature Count': len(clustering_results.get('features', [])),
                'Record Count': len(st.session_state.cluster_labels) if 'cluster_labels' in st.session_state else 'N/A'
            })

        # é£é™©è¯„åˆ†åˆ†æ
        if 'risk_analysis' in report_data:
            risk_analysis = report_data['risk_analysis']
            analysis_summary.append({
                'Analysis Item': 'Risk Scoring',
                'Average Score': f"{risk_analysis['score_stats']['mean']:.2f}",
                'Standard Deviation': f"{risk_analysis['score_stats']['std']:.2f}",
                'Highest Score': f"{risk_analysis['score_stats']['max']:.2f}",
                'Lowest Score': f"{risk_analysis['score_stats']['min']:.2f}"
            })

        # æ¨¡å‹æ€§èƒ½åˆ†æ
        if 'model_performance' in report_data:
            model_performance = report_data['model_performance']
            if model_performance:
                best_model = max(model_performance.items(), key=lambda x: x[1].get('accuracy', 0))[0]
                best_accuracy = model_performance[best_model].get('accuracy', 0)
                analysis_summary.append({
                    'Analysis Item': 'Model Performance',
                    'Best Model': best_model,
                    'Best Accuracy': f"{best_accuracy:.3f}",
                    'Model Count': len(model_performance),
                    'Average Accuracy': f"{np.mean([p.get('accuracy', 0) for p in model_performance.values()]):.3f}"
                })
        
        # æ”»å‡»åˆ†æ
        if 'attack_analysis' in report_data:
            attack_analysis = report_data['attack_analysis']

            # å®‰å…¨åœ°è·å–ç½®ä¿¡åº¦æ•°æ®
            try:
                if 'attack_results' in st.session_state and st.session_state.attack_results:
                    attack_results = st.session_state.attack_results
                    if isinstance(attack_results, dict):
                        attack_data = attack_results.get('attack_predictions', [])
                    elif isinstance(attack_results, list):
                        attack_data = attack_results
                    else:
                        attack_data = []

                    if attack_data and isinstance(attack_data, list):
                        confidences = [r.get('confidence', 0) for r in attack_data if isinstance(r, dict) and 'confidence' in r]
                        avg_confidence = np.mean(confidences) if confidences else 0
                    else:
                        avg_confidence = 0
                else:
                    avg_confidence = 0
            except Exception:
                avg_confidence = 0

            analysis_summary.append({
                'Analysis Item': 'Attack Detection',
                'Detected Attacks': attack_analysis.get('total_attacks', 0),
                'Attack Types': len(attack_analysis.get('attack_types', {})),
                'High Risk Rate': f"{attack_analysis.get('severity_distribution', {}).get('high', 0) / max(attack_analysis.get('total_attacks', 1), 1) * 100:.2f}%",
                'Average Confidence': f"{avg_confidence:.3f}"
            })
        
        # æ˜¾ç¤ºç»¼åˆåˆ†æè¡¨æ ¼
        if analysis_summary:
            summary_df = pd.DataFrame(analysis_summary)
            st.dataframe(summary_df, use_container_width=True)
        
        # æŠ¥å‘Šå¯¼å‡º
        st.markdown("#### ğŸ“„ Report Export")

        col1, col2, col3 = st.columns(3)

        with col1:
            if st.button("ğŸ“Š Export PDF Report", type="primary", use_container_width=True):
                if report_data is None:
                    st.error("âŒ Please generate analysis report first")
                else:
                    try:
                        report_generator = ReportGenerator()
                        pdf_path = report_generator.generate_pdf_report(report_data)
                        st.success(f"âœ… PDF report generated: {pdf_path}")

                        # æä¾›ä¸‹è½½é“¾æ¥
                        if os.path.exists(pdf_path):
                            with open(pdf_path, "rb") as file:
                                st.download_button(
                                    label="ğŸ“¥ Download PDF Report",
                                    data=file.read(),
                                    file_name="fraud_detection_report.pdf",
                                    mime="application/pdf"
                                )
                        else:
                            st.warning("âš ï¸ PDF file generation failed")
                    except Exception as e:
                        st.error(f"âŒ PDF report generation failed: {str(e)}")
                        st.info("ğŸ’¡ PDF report feature is under development, please try other formats")

        with col2:
            if st.button("ğŸ“Š Export Excel Report", type="primary", use_container_width=True):
                if report_data is None:
                    st.error("âŒ Please generate analysis report first")
                else:
                    try:
                        report_generator = ReportGenerator()
                        excel_path = report_generator.generate_excel_report(report_data)
                        st.success(f"âœ… Excel report generated: {excel_path}")

                        # æä¾›ä¸‹è½½é“¾æ¥
                        if os.path.exists(excel_path):
                            with open(excel_path, "rb") as file:
                                st.download_button(
                                    label="ğŸ“¥ Download Excel Report",
                                    data=file.read(),
                                    file_name="fraud_detection_report.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                                )
                        else:
                            st.warning("âš ï¸ Excelæ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                    except Exception as e:
                        st.error(f"âŒ ExcelæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")

        with col3:
            if st.button("ğŸ“Š å¯¼å‡ºHTMLæŠ¥å‘Š", type="primary", use_container_width=True):
                if report_data is None:
                    st.error("âŒ è¯·å…ˆç”Ÿæˆåˆ†ææŠ¥å‘Š")
                else:
                    try:
                        report_generator = ReportGenerator()
                        html_path = report_generator.generate_html_report(report_data)
                        st.success(f"âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_path}")

                        # æä¾›ä¸‹è½½é“¾æ¥
                        if os.path.exists(html_path):
                            with open(html_path, "r", encoding="utf-8") as file:
                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½HTMLæŠ¥å‘Š",
                                    data=file.read(),
                                    file_name="fraud_detection_report.html",
                                    mime="text/html"
                                )
                        else:
                            st.warning("âš ï¸ HTMLæ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                    except Exception as e:
                        st.error(f"âŒ HTMLæŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
        
        # æŠ¥å‘Šå®Œæˆ
        st.markdown("---")
        st.success("ğŸ‰ Congratulations! You have completed the entire e-commerce fraud risk prediction system analysis process!")
        st.markdown("""
        **Analysis Process Summary:**
        1. âœ… Data upload and preprocessing
        2. âœ… Feature engineering and risk feature generation
        3. âœ… Clustering analysis and anomalous group identification
        4. âœ… Risk scoring and level classification
        5. âœ… Multi-model prediction and performance comparison
        6. âœ… Attack type classification and protection recommendations
        7. âœ… Comprehensive analysis report and explainability analysis

        **System Features:**
        - Multi-dimensional risk assessment
        - Intelligent feature engineering
        - Multi-model ensemble prediction
        - Attack type identification
        - Explainability analysis
        - Comprehensive report generation
        """)
    
    else:
        # æ˜¾ç¤ºåˆ†ææŠ¥å‘Šè¯´æ˜
        st.markdown("### ğŸ“ Analysis Report Description")
        
        st.markdown("""
        **Report Content:**

        1. **Data Analysis Report**
           - Data quality assessment
           - Feature distribution analysis
           - Data statistical information

        2. **Model Performance Report**
           - Multi-model comparison analysis
           - Performance metrics explanation
           - Prediction result statistics

        3. **Risk Assessment Report**
           - Risk level distribution
           - Risk score analysis
           - Risk trend analysis

        4. **Attack Analysis Report**
           - Attack type statistics
           - Attack severity analysis
           - Attack feature analysis

        5. **Explainability Report**
           - SHAP global feature importance
           - LIME local explanation analysis
           - Feature contribution analysis

        6. **Protection Recommendation Report**
           - Overall protection recommendations
           - Targeted protection measures
           - Emergency handling recommendations

        **Explainability Analysis:**
        - **SHAP Analysis**: Global feature importance and local feature contribution
        - **LIME Analysis**: Local linear explanation for individual predictions
        - **Feature Interaction**: Analysis of interactions between features
        - **Decision Path**: Visualization of model decision process
        """)