"""
ä¼ªæ ‡ç­¾ç”Ÿæˆé¡µé¢
æä¾›å¤šç§ç­–ç•¥çš„ä¼ªæ ‡ç­¾ç”Ÿæˆå’Œè´¨é‡è¯„ä¼°åŠŸèƒ½
"""

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# å¯¼å…¥åç«¯æ¨¡å—
from backend.pseudo_labeling.pseudo_label_generator import PseudoLabelGenerator
from backend.pseudo_labeling.fast_pseudo_label_generator import FastPseudoLabelGenerator

def show():
    """æ˜¾ç¤ºä¼ªæ ‡ç­¾ç”Ÿæˆé¡µé¢"""
    st.markdown('<div class="sub-header">ğŸ·ï¸ æ™ºèƒ½ä¼ªæ ‡ç­¾ç”Ÿæˆç³»ç»Ÿ</div>', unsafe_allow_html=True)

    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    if not _check_prerequisites():
        return

    # åˆå§‹åŒ–session state
    _initialize_session_state()

    engineered_data = st.session_state.engineered_features

    # æ˜¾ç¤ºç³»ç»Ÿè¯´æ˜
    _show_system_description()

    # æ•°æ®æ¦‚è§ˆ
    _show_data_overview(engineered_data)

    # ä¼ªæ ‡ç­¾ç”Ÿæˆé…ç½®
    _show_generation_config()

    # æ‰§è¡Œä¼ªæ ‡ç­¾ç”Ÿæˆ
    mode = st.session_state.label_generation_mode
    button_text = "ğŸ” ç”Ÿæˆé«˜è´¨é‡ä¼ªæ ‡ç­¾ (æ ‡å‡†æ¨¡å¼)" if mode == "standard" else "âš¡ å¿«é€Ÿç”Ÿæˆä¼ªæ ‡ç­¾ (å¿«é€Ÿæ¨¡å¼)"
    button_help = "å¤šç­–ç•¥é›†æˆï¼Œé«˜è´¨é‡æ ‡ç­¾ï¼Œ2-3åˆ†é’Ÿå®Œæˆ" if mode == "standard" else "ç®€åŒ–ç®—æ³•ï¼Œå¿«é€Ÿç”Ÿæˆï¼Œ30ç§’å†…å®Œæˆ"

    if st.button(button_text, type="primary", help=button_help):
        _execute_pseudo_label_generation(engineered_data)

    # æ˜¾ç¤ºä¼ªæ ‡ç­¾ç»“æœ
    if st.session_state.pseudo_labels:
        _show_pseudo_label_results()

        # è´¨é‡è¯„ä¼°
        _show_quality_assessment()

        # æ ‡ç­¾å¯¼å‡º
        _show_label_export()


def _check_prerequisites():
    """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
    if 'engineered_features' not in st.session_state or st.session_state.engineered_features is None:
        st.warning("âš ï¸ è¯·å…ˆå®Œæˆç‰¹å¾å·¥ç¨‹ï¼")
        st.info("ğŸ’¡ è¯·åœ¨'ğŸ”§ ç‰¹å¾å·¥ç¨‹'é¡µé¢å®Œæˆç‰¹å¾ç”Ÿæˆ")
        return False
    return True


def _initialize_session_state():
    """åˆå§‹åŒ–session state"""
    if 'pseudo_labels' not in st.session_state:
        st.session_state.pseudo_labels = None
    if 'label_generator' not in st.session_state:
        st.session_state.label_generator = PseudoLabelGenerator()
    if 'fast_label_generator' not in st.session_state:
        st.session_state.fast_label_generator = FastPseudoLabelGenerator()
    if 'high_quality_labels' not in st.session_state:
        st.session_state.high_quality_labels = None
    if 'label_generation_mode' not in st.session_state:
        st.session_state.label_generation_mode = "standard"


def _show_system_description():
    """æ˜¾ç¤ºç³»ç»Ÿè¯´æ˜"""
    with st.expander("ğŸ“– æ™ºèƒ½ä¼ªæ ‡ç­¾ç”Ÿæˆç³»ç»Ÿè¯´æ˜", expanded=False):
        st.markdown("""
        ### ğŸ¯ ç³»ç»Ÿç‰¹ç‚¹
        - **æ— ç›‘ç£é©±åŠ¨**: åŸºäºèšç±»åˆ†æå’Œæ— ç›‘ç£é£é™©è¯„åˆ†ç”Ÿæˆä¼ªæ ‡ç­¾
        - **å¤šç­–ç•¥é›†æˆ**: èåˆé£é™©è¯„åˆ†ã€èšç±»åˆ†æã€ä¸“å®¶è§„åˆ™ä¸‰ç§ç­–ç•¥
        - **è´¨é‡ä¼˜å…ˆ**: è‡ªåŠ¨ç­›é€‰é«˜ç½®ä¿¡åº¦æ ‡ç­¾ï¼Œç¡®ä¿æ ‡ç­¾è´¨é‡
        - **æ™ºèƒ½æ ¡å‡†**: å¯é€‰ä½¿ç”¨å°‘é‡çœŸå®æ ‡ç­¾è¿›è¡Œæ ¡å‡†ä¼˜åŒ–

        ### ğŸ“Š ç”Ÿæˆç­–ç•¥
        1. **æ— ç›‘ç£é£é™©è¯„åˆ†** (45%): åŸºäºèšç±»å¼‚å¸¸åº¦å’Œç‰¹å¾åç¦»åº¦
        2. **èšç±»é£é™©æ˜ å°„** (35%): åŸºäºèšç±»è´¨é‡å’Œé£é™©ç­‰çº§
        3. **ä¸“å®¶ä¸šåŠ¡è§„åˆ™** (20%): åŸºäºé¢†åŸŸçŸ¥è¯†çš„è§„åˆ™åŒ¹é…

        ### ğŸ”§ è´¨é‡æ§åˆ¶
        - **åŠ¨æ€æƒé‡**: æ ¹æ®å„ç­–ç•¥è´¨é‡è‡ªåŠ¨è°ƒæ•´æƒé‡
        - **ç½®ä¿¡åº¦ç­›é€‰**: åªä¿ç•™é«˜ç½®ä¿¡åº¦çš„ä¼ªæ ‡ç­¾
        - **ä¸€è‡´æ€§æ£€éªŒ**: å¤šç­–ç•¥ä¸€è‡´æ€§è¶Šé«˜ï¼Œç½®ä¿¡åº¦è¶Šé«˜
        - **å¹³è¡¡æ€§ä¼˜åŒ–**: è‡ªåŠ¨è°ƒæ•´æ ‡ç­¾åˆ†å¸ƒï¼Œé¿å…æç«¯ä¸å¹³è¡¡
        """)


def _show_data_overview(engineered_data):
    """æ˜¾ç¤ºæ•°æ®æ¦‚è§ˆ"""
    st.markdown("### ğŸ“Š æ•°æ®æ¦‚è§ˆ")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("æ€»æ ·æœ¬æ•°", f"{len(engineered_data):,}")

    with col2:
        if 'is_fraudulent' in engineered_data.columns:
            true_fraud_rate = round(engineered_data['is_fraudulent'].sum() / len(engineered_data) * 100, 2)
            st.metric("çœŸå®æ¬ºè¯ˆç‡", f"{true_fraud_rate}%")
        else:
            st.metric("çœŸå®æ¬ºè¯ˆç‡", "N/A")

    with col3:
        st.metric("ç‰¹å¾æ•°é‡", f"{len(engineered_data.columns)}")

    with col4:
        # æ£€æŸ¥æ˜¯å¦æœ‰æ— ç›‘ç£é£é™©è¯„åˆ†ç»“æœ
        if st.session_state.get('unsupervised_risk_results'):
            avg_risk = st.session_state.unsupervised_risk_results.get('average_risk_score', 0)
            st.metric("å¹³å‡é£é™©è¯„åˆ†", f"{avg_risk:.1f}")
        else:
            st.metric("å¹³å‡é£é™©è¯„åˆ†", "å¾…è®¡ç®—")


def _show_generation_config():
    """æ˜¾ç¤ºç”Ÿæˆé…ç½®"""
    st.markdown("### âš™ï¸ ä¼ªæ ‡ç­¾ç”Ÿæˆé…ç½®")

    # ç”Ÿæˆæ¨¡å¼é€‰æ‹©
    st.markdown("#### ğŸ¯ ç”Ÿæˆæ¨¡å¼é€‰æ‹©")

    col_mode1, col_mode2 = st.columns(2)

    with col_mode1:
        if st.button("ğŸ” æ ‡å‡†æ¨¡å¼", use_container_width=True,
                    help="å®Œæ•´ç­–ç•¥é›†æˆï¼Œé«˜è´¨é‡æ ‡ç­¾ï¼Œ2-3åˆ†é’Ÿå®Œæˆ"):
            st.session_state.label_generation_mode = "standard"

    with col_mode2:
        if st.button("âš¡ å¿«é€Ÿæ¨¡å¼", use_container_width=True,
                    help="ç®€åŒ–ç®—æ³•ï¼Œå¿«é€Ÿç”Ÿæˆï¼Œ30ç§’å†…å®Œæˆ"):
            st.session_state.label_generation_mode = "fast"

    # æ˜¾ç¤ºå½“å‰æ¨¡å¼
    mode = st.session_state.label_generation_mode
    if mode == "standard":
        st.success("ğŸ” **å½“å‰æ¨¡å¼: æ ‡å‡†æ¨¡å¼** - å¤šç­–ç•¥é›†æˆï¼Œé«˜è´¨é‡æ ‡ç­¾")
    else:
        st.info("âš¡ **å½“å‰æ¨¡å¼: å¿«é€Ÿæ¨¡å¼** - ç®€åŒ–ç®—æ³•ï¼Œå¿«é€Ÿç”Ÿæˆ")

    st.markdown("---")

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**è´¨é‡æ§åˆ¶å‚æ•°**")
        min_confidence = st.slider(
            "æœ€å°ç½®ä¿¡åº¦é˜ˆå€¼",
            min_value=0.5,
            max_value=0.95,
            value=0.8,
            step=0.05,
            help="åªä¿ç•™ç½®ä¿¡åº¦é«˜äºæ­¤é˜ˆå€¼çš„ä¼ªæ ‡ç­¾"
        )

        use_calibration = st.checkbox(
            "å¯ç”¨æ ¡å‡†ä¼˜åŒ–",
            value=True,
            help="ä½¿ç”¨å°‘é‡çœŸå®æ ‡ç­¾æ ¡å‡†é£é™©è¯„åˆ†é˜ˆå€¼"
        )

        balance_labels = st.checkbox(
            "æ ‡ç­¾å¹³è¡¡ä¼˜åŒ–",
            value=True,
            help="è‡ªåŠ¨è°ƒæ•´æ ‡ç­¾åˆ†å¸ƒï¼Œé¿å…æç«¯ä¸å¹³è¡¡"
        )

    with col2:
        st.markdown("**ç­–ç•¥æƒé‡é…ç½®**")

        # æ˜¾ç¤ºå½“å‰æƒé‡é…ç½®
        current_weights = {
            "æ— ç›‘ç£é£é™©è¯„åˆ†": 45,
            "èšç±»é£é™©æ˜ å°„": 35,
            "ä¸“å®¶ä¸šåŠ¡è§„åˆ™": 20
        }

        for strategy, weight in current_weights.items():
            st.write(f"- {strategy}: {weight}%")

        st.info("ğŸ’¡ æƒé‡ä¼šæ ¹æ®å„ç­–ç•¥çš„å®é™…è´¨é‡åŠ¨æ€è°ƒæ•´")

    # ä¿å­˜é…ç½®åˆ°session state
    st.session_state.label_config = {
        'min_confidence': min_confidence,
        'use_calibration': use_calibration,
        'balance_labels': balance_labels
    }
    
    # é«˜çº§é…ç½®ï¼ˆä»…æ ‡å‡†æ¨¡å¼æ˜¾ç¤ºï¼‰
    if mode == "standard":
        st.markdown("#### ğŸ”§ é«˜çº§é…ç½®")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        strategy = st.selectbox(
            "é€‰æ‹©æ ‡ç­¾ç”Ÿæˆç­–ç•¥",
            options=['ensemble', 'risk_based', 'cluster_based', 'rule_based'],
            format_func=lambda x: {
                'ensemble': 'ğŸ¯ é›†æˆç­–ç•¥ (æ¨è)',
                'risk_based': 'ğŸ“Š åŸºäºé£é™©è¯„åˆ†',
                'cluster_based': 'ğŸ” åŸºäºèšç±»åˆ†æ',
                'rule_based': 'ğŸ“‹ åŸºäºä¸“å®¶è§„åˆ™'
            }[x],
            help="é€‰æ‹©ä¼ªæ ‡ç­¾ç”Ÿæˆç­–ç•¥"
        )
    
    with col2:
        confidence_threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            min_value=0.1,
            max_value=0.9,
            value=0.7,
            step=0.05,
            help="åªä¿ç•™ç½®ä¿¡åº¦é«˜äºæ­¤é˜ˆå€¼çš„æ ‡ç­¾"
        )
    
    # ç­–ç•¥è¯´æ˜
    strategy_descriptions = {
        'ensemble': """
        **ğŸ¯ é›†æˆç­–ç•¥**
        - ç»¼åˆé£é™©è¯„åˆ†ã€èšç±»åˆ†æå’Œä¸“å®¶è§„åˆ™
        - ä½¿ç”¨åŠ æƒæŠ•ç¥¨æœºåˆ¶
        - æä¾›æœ€é«˜çš„æ ‡ç­¾è´¨é‡å’Œç¨³å®šæ€§
        """,
        'risk_based': """
        **ğŸ“Š åŸºäºé£é™©è¯„åˆ†**
        - æ ¹æ®å¤šç»´åº¦é£é™©è¯„åˆ†ç”Ÿæˆæ ‡ç­¾
        - é«˜é£é™©è¯„åˆ†(>70) â†’ æ¬ºè¯ˆæ ‡ç­¾
        - é€‚åˆæœ‰æ˜ç¡®é£é™©é˜ˆå€¼çš„åœºæ™¯
        """,
        'cluster_based': """
        **ğŸ” åŸºäºèšç±»åˆ†æ**
        - æ ¹æ®èšç±»çš„æ¬ºè¯ˆç‡ç”Ÿæˆæ ‡ç­¾
        - é«˜æ¬ºè¯ˆç‡èšç±» â†’ æ¬ºè¯ˆæ ‡ç­¾
        - é€‚åˆå‘ç°éšè—çš„æ¬ºè¯ˆæ¨¡å¼
        """,
        'rule_based': """
        **ğŸ“‹ åŸºäºä¸“å®¶è§„åˆ™**
        - åŸºäºä¸šåŠ¡ä¸“å®¶ç»éªŒè§„åˆ™
        - åŒ…å«æ—¶é—´ã€é‡‘é¢ã€è®¾å¤‡ç­‰è§„åˆ™
        - é€‚åˆæœ‰æ˜ç¡®ä¸šåŠ¡é€»è¾‘çš„åœºæ™¯
        """
    }
    
    st.markdown(strategy_descriptions[strategy])
    
    # æ‰§è¡Œä¼ªæ ‡ç­¾ç”Ÿæˆ
    col1, col2 = st.columns([3, 1])
    
    with col1:
        generate_labels = st.button("ğŸš€ ç”Ÿæˆä¼ªæ ‡ç­¾", type="primary", help="åŸºäºé€‰æ‹©çš„ç­–ç•¥ç”Ÿæˆä¼ªæ ‡ç­¾")
    
    with col2:
        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç»“æœ", help="æ¸…é™¤ä¹‹å‰çš„ç”Ÿæˆç»“æœ"):
            st.session_state.pseudo_labels = None
            st.success("âœ… ç»“æœå·²æ¸…é™¤ï¼")
            st.rerun()
    
    if generate_labels:
        try:
            # è·å–å·¥ç¨‹åŒ–ç‰¹å¾æ•°æ®
            engineered_data = st.session_state.engineered_features
            if engineered_data is None or engineered_data.empty:
                st.error("âŒ è¯·å…ˆå®Œæˆç‰¹å¾å·¥ç¨‹æ­¥éª¤ï¼")
                return

            with st.spinner("æ­£åœ¨ç”Ÿæˆä¼ªæ ‡ç­¾..."):
                # æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼
                st.session_state.label_generator.update_confidence_threshold(confidence_threshold)

                # ç”Ÿæˆä¼ªæ ‡ç­¾
                pseudo_results = st.session_state.label_generator.generate_pseudo_labels(
                    engineered_data, strategy=strategy
                )

                # ä¿å­˜ç»“æœ
                st.session_state.pseudo_labels = pseudo_results

                st.success("âœ… ä¼ªæ ‡ç­¾ç”Ÿæˆå®Œæˆï¼")

        except Exception as e:
            st.error(f"âŒ ä¼ªæ ‡ç­¾ç”Ÿæˆå¤±è´¥: {e}")
            st.exception(e)
    
    # æ˜¾ç¤ºä¼ªæ ‡ç­¾ç»“æœ
    if st.session_state.pseudo_labels is not None:
        st.markdown("### ğŸ“ˆ ä¼ªæ ‡ç­¾ç”Ÿæˆç»“æœ")
        
        pseudo_results = st.session_state.pseudo_labels
        
        # åŸºæœ¬ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç”Ÿæˆç­–ç•¥", pseudo_results['strategy'].upper())
        
        with col2:
            # å…¼å®¹ä¸åŒæ¨¡å¼çš„æ•°æ®ç»“æ„
            all_labels = pseudo_results.get('all_labels', pseudo_results.get('labels', []))
            total_labels = len(all_labels)
            st.metric("æ ‡ç­¾æ€»æ•°", f"{total_labels:,}")

        with col3:
            # å…¼å®¹ä¸åŒçš„ç½®ä¿¡åº¦å­—æ®µ
            if 'metadata' in pseudo_results:
                avg_confidence = pseudo_results['metadata'].get('avg_confidence_all', 0)
            else:
                avg_confidence = pseudo_results.get('avg_confidence', 0)
            st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.3f}")

        with col4:
            # å…¼å®¹ä¸åŒçš„é«˜ç½®ä¿¡åº¦è®¡æ•°å­—æ®µ
            if 'metadata' in pseudo_results:
                high_conf_count = pseudo_results['metadata'].get('high_quality_count', 0)
            else:
                high_conf_count = pseudo_results.get('high_confidence_count', 0)
            high_conf_rate = high_conf_count / total_labels * 100 if total_labels > 0 else 0
            st.metric("é«˜ç½®ä¿¡åº¦æ¯”ä¾‹", f"{high_conf_rate:.1f}%")
        
        # æ ‡ç­¾åˆ†å¸ƒ
        st.markdown("#### ğŸ“Š æ ‡ç­¾åˆ†å¸ƒåˆ†æ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # æ ‡ç­¾åˆ†å¸ƒé¥¼å›¾
            # å…¼å®¹ä¸åŒæ¨¡å¼çš„æ•°æ®ç»“æ„
            all_labels = pseudo_results.get('all_labels', pseudo_results.get('labels', []))
            if all_labels:
                label_counts = pd.Series(all_labels).value_counts()

                fig = px.pie(
                    values=label_counts.values,
                    names=['æ­£å¸¸äº¤æ˜“', 'æ¬ºè¯ˆäº¤æ˜“'],
                    title="ä¼ªæ ‡ç­¾åˆ†å¸ƒ",
                    color_discrete_map={
                        'æ­£å¸¸äº¤æ˜“': '#2E8B57',
                        'æ¬ºè¯ˆäº¤æ˜“': '#DC143C'
                    }
                )
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("âš ï¸ æ— æ ‡ç­¾æ•°æ®å¯æ˜¾ç¤º")

        with col2:
            # ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
            # å…¼å®¹ä¸åŒçš„ç½®ä¿¡åº¦å­—æ®µ
            confidences = pseudo_results.get('all_confidences', pseudo_results.get('confidences', []))

            if confidences:
                fig = px.histogram(
                    x=confidences,
                    title="ç½®ä¿¡åº¦åˆ†å¸ƒ",
                    nbins=20,
                    labels={'x': 'ç½®ä¿¡åº¦', 'y': 'é¢‘æ¬¡'}
                )
                fig.add_vline(x=confidence_threshold, line_dash="dash", line_color="red",
                             annotation_text=f"é˜ˆå€¼: {confidence_threshold}")
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.warning("âš ï¸ æ— ç½®ä¿¡åº¦æ•°æ®å¯æ˜¾ç¤º")
        
        # è´¨é‡è¯„ä¼°
        st.markdown("#### ğŸ¯ æ ‡ç­¾è´¨é‡è¯„ä¼°")
        
        # å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œè®¡ç®—å‡†ç¡®æ€§æŒ‡æ ‡
        if 'is_fraudulent' in engineered_data.columns:
            true_labels = engineered_data['is_fraudulent'].tolist()
            # å…¼å®¹ä¸åŒæ¨¡å¼çš„æ ‡ç­¾å­—æ®µ
            all_labels = pseudo_results.get('all_labels', pseudo_results.get('labels', []))

            if all_labels and len(all_labels) == len(true_labels):
                try:
                    quality_metrics = st.session_state.label_generator.get_label_quality_metrics(
                        all_labels, true_labels
                    )

                    col1, col2, col3, col4 = st.columns(4)

                    with col1:
                        st.metric("å‡†ç¡®ç‡", f"{quality_metrics['accuracy']:.3f}")

                    with col2:
                        st.metric("ç²¾ç¡®ç‡", f"{quality_metrics['precision']:.3f}")

                    with col3:
                        st.metric("å¬å›ç‡", f"{quality_metrics['recall']:.3f}")

                    with col4:
                        st.metric("F1åˆ†æ•°", f"{quality_metrics['f1_score']:.3f}")

                    # æ··æ·†çŸ©é˜µ
                    from sklearn.metrics import confusion_matrix
                    cm = confusion_matrix(true_labels, all_labels)

                    fig = px.imshow(
                        cm,
                        text_auto=True,
                        aspect="auto",
                        title="æ··æ·†çŸ©é˜µ",
                        labels=dict(x="é¢„æµ‹æ ‡ç­¾", y="çœŸå®æ ‡ç­¾"),
                        x=['æ­£å¸¸', 'æ¬ºè¯ˆ'],
                        y=['æ­£å¸¸', 'æ¬ºè¯ˆ']
                    )
                    st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.warning(f"âš ï¸ è´¨é‡è¯„ä¼°è®¡ç®—å¤±è´¥: {str(e)}")
            else:
                st.info("ğŸ’¡ æ ‡ç­¾æ•°é‡ä¸åŒ¹é…ï¼Œè·³è¿‡è´¨é‡è¯„ä¼°")

        # ä¸‹ä¸€æ­¥æŒ‰é’®
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])

        with col2:
            if st.button("ğŸ¤– ä¸‹ä¸€æ­¥ï¼šæ¨¡å‹è®­ç»ƒ", type="primary", use_container_width=True):
                st.success("âœ… ä¼ªæ ‡ç­¾ç”Ÿæˆå®Œæˆï¼Œå¯ä»¥è¿›å…¥æ¨¡å‹è®­ç»ƒé¡µé¢ï¼")
                st.info("ğŸ’¡ è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©'ğŸ¤– æ¨¡å‹è®­ç»ƒ'é¡µé¢ç»§ç»­")


def _execute_pseudo_label_generation(engineered_data):
    """æ‰§è¡Œä¼ªæ ‡ç­¾ç”Ÿæˆ"""
    try:
        config = st.session_state.label_config
        mode = st.session_state.label_generation_mode

        mode_text = "æ ‡å‡†æ¨¡å¼" if mode == "standard" else "å¿«é€Ÿæ¨¡å¼"
        mode_icon = "ğŸ”" if mode == "standard" else "âš¡"

        with st.spinner(f"æ­£åœ¨ä½¿ç”¨{mode_text}ç”Ÿæˆä¼ªæ ‡ç­¾..."):
            # è®°å½•å¼€å§‹æ—¶é—´
            import time
            start_time = time.time()

            # æ ¹æ®æ¨¡å¼é€‰æ‹©ç”Ÿæˆå™¨
            if mode == "standard":
                # ä½¿ç”¨æ ‡å‡†æ¨¡å¼ç”Ÿæˆå™¨
                label_results = st.session_state.label_generator.generate_high_quality_pseudo_labels(
                    engineered_data,
                    min_confidence=config['min_confidence'],
                    use_calibration=config['use_calibration']
                )
            else:
                # ä½¿ç”¨å¿«é€Ÿæ¨¡å¼ç”Ÿæˆå™¨
                risk_results = st.session_state.get('unsupervised_risk_results', None)
                label_results = st.session_state.fast_label_generator.generate_fast_pseudo_labels(
                    engineered_data,
                    risk_results=risk_results,
                    min_confidence=config['min_confidence']
                )

            # è®°å½•ç»“æŸæ—¶é—´
            end_time = time.time()
            generation_time = end_time - start_time

            st.session_state.pseudo_labels = label_results
            st.session_state.high_quality_labels = label_results

            if label_results and label_results.get('high_quality_labels'):
                total_labels = len(label_results.get('all_labels', []))
                hq_labels = len(label_results.get('high_quality_labels', []))

                success_msg = f"âœ… {mode_icon} {mode_text}ä¼ªæ ‡ç­¾ç”Ÿæˆå®Œæˆï¼"
                success_msg += f" ä» {total_labels} ä¸ªæ ·æœ¬ä¸­ç­›é€‰å‡º {hq_labels} ä¸ªé«˜è´¨é‡æ ‡ç­¾ï¼Œè€—æ—¶ {generation_time:.2f} ç§’"
                st.success(success_msg)

                # æ˜¾ç¤ºåŸºæœ¬ç»Ÿè®¡
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    hq_rate = label_results['metadata']['high_quality_rate']
                    st.metric("é«˜è´¨é‡æ¯”ä¾‹", f"{hq_rate:.1%}")

                with col2:
                    avg_conf_hq = label_results['metadata']['avg_confidence_hq']
                    st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_conf_hq:.3f}")

                with col3:
                    fraud_rate_hq = label_results['metadata']['fraud_rate_hq']
                    st.metric("ä¼ªæ ‡ç­¾æ¬ºè¯ˆç‡", f"{fraud_rate_hq:.1%}")

                with col4:
                    quality_score = label_results['quality_report'].get('quality_score', 0)
                    st.metric("è´¨é‡è¯„åˆ†", f"{quality_score:.1f}")

                # æ˜¾ç¤ºæ ¡å‡†çŠ¶æ€
                if label_results.get('calibration_applied'):
                    st.info("âœ… å·²åº”ç”¨æ ¡å‡†ä¼˜åŒ–ï¼Œé£é™©è¯„åˆ†é˜ˆå€¼å·²ä¼˜åŒ–")
                elif config['use_calibration']:
                    st.warning("âš ï¸ æ ¡å‡†æœªæˆåŠŸåº”ç”¨ï¼Œä½¿ç”¨é»˜è®¤é˜ˆå€¼")

            else:
                st.error("âŒ æœªèƒ½ç”Ÿæˆè¶³å¤Ÿçš„é«˜è´¨é‡ä¼ªæ ‡ç­¾ï¼Œè¯·é™ä½ç½®ä¿¡åº¦é˜ˆå€¼")

    except Exception as e:
        st.error(f"âŒ ä¼ªæ ‡ç­¾ç”Ÿæˆå¤±è´¥: {str(e)}")


def _show_pseudo_label_results():
    """æ˜¾ç¤ºä¼ªæ ‡ç­¾ç»“æœ"""
    st.markdown("### ğŸ“ˆ é«˜è´¨é‡ä¼ªæ ‡ç­¾ç»“æœ")

    label_results = st.session_state.pseudo_labels

    # ç»“æœæ¦‚è§ˆ
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**æ ‡ç­¾åˆ†å¸ƒå¯¹æ¯”**")

        all_labels = label_results.get('all_labels', [])
        hq_labels = label_results.get('high_quality_labels', [])

        # åˆ›å»ºå¯¹æ¯”æ•°æ®
        all_dist = pd.Series(all_labels).value_counts()
        hq_dist = pd.Series(hq_labels).value_counts() if hq_labels else pd.Series()

        # ç¡®ä¿åŒ…å«æ‰€æœ‰å¯èƒ½çš„æ ‡ç­¾ç±»åˆ«
        all_dist = all_dist.reindex([0, 1], fill_value=0)
        hq_dist = hq_dist.reindex([0, 1], fill_value=0)

        comparison_data = pd.DataFrame({
            'å…¨éƒ¨æ ‡ç­¾': all_dist,
            'é«˜è´¨é‡æ ‡ç­¾': hq_dist
        }).fillna(0)

        comparison_data.index = ['æ­£å¸¸', 'æ¬ºè¯ˆ']

        fig = px.bar(
            comparison_data,
            title="æ ‡ç­¾åˆ†å¸ƒå¯¹æ¯”",
            labels={'index': 'æ ‡ç­¾ç±»å‹', 'value': 'æ•°é‡'},
            color_discrete_map={'å…¨éƒ¨æ ‡ç­¾': '#17a2b8', 'é«˜è´¨é‡æ ‡ç­¾': '#28a745'}
        )
        st.plotly_chart(fig, use_container_width=True)

    with col2:
        st.markdown("**ç½®ä¿¡åº¦åˆ†å¸ƒ**")

        all_confidences = label_results.get('all_confidences', [])
        hq_confidences = label_results.get('high_quality_confidences', [])

        if all_confidences:
            fig = go.Figure()

            fig.add_trace(go.Histogram(
                x=all_confidences,
                name='å…¨éƒ¨æ ‡ç­¾',
                opacity=0.7,
                nbinsx=20
            ))

            if hq_confidences:
                fig.add_trace(go.Histogram(
                    x=hq_confidences,
                    name='é«˜è´¨é‡æ ‡ç­¾',
                    opacity=0.7,
                    nbinsx=20
                ))

            fig.add_vline(
                x=label_results['min_confidence_threshold'],
                line_dash="dash",
                line_color="red",
                annotation_text="ç½®ä¿¡åº¦é˜ˆå€¼"
            )

            fig.update_layout(
                title="ç½®ä¿¡åº¦åˆ†å¸ƒå¯¹æ¯”",
                xaxis_title="ç½®ä¿¡åº¦",
                yaxis_title="é¢‘æ¬¡",
                barmode='overlay'
            )

            st.plotly_chart(fig, use_container_width=True)


def _show_quality_assessment():
    """æ˜¾ç¤ºè´¨é‡è¯„ä¼°"""
    st.markdown("### ğŸ¯ è´¨é‡è¯„ä¼°ä¸éªŒè¯")

    label_results = st.session_state.pseudo_labels
    engineered_data = st.session_state.engineered_features

    # å¦‚æœæœ‰çœŸå®æ ‡ç­¾ï¼Œè¿›è¡Œå¯¹æ¯”éªŒè¯
    if 'is_fraudulent' in engineered_data.columns:
        st.markdown("**ä¸çœŸå®æ ‡ç­¾å¯¹æ¯”éªŒè¯**")

        hq_indices = label_results.get('high_quality_indices', [])
        hq_labels = label_results.get('high_quality_labels', [])

        if hq_indices and hq_labels:
            # è·å–å¯¹åº”çš„çœŸå®æ ‡ç­¾
            true_labels_hq = [engineered_data.iloc[i]['is_fraudulent'] for i in hq_indices]

            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix

            accuracy = accuracy_score(true_labels_hq, hq_labels)
            precision = precision_score(true_labels_hq, hq_labels, zero_division=0)
            recall = recall_score(true_labels_hq, hq_labels, zero_division=0)
            f1 = f1_score(true_labels_hq, hq_labels, zero_division=0)

            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("å‡†ç¡®ç‡", f"{accuracy:.3f}")

            with col2:
                st.metric("ç²¾ç¡®ç‡", f"{precision:.3f}")

            with col3:
                st.metric("å¬å›ç‡", f"{recall:.3f}")

            with col4:
                st.metric("F1åˆ†æ•°", f"{f1:.3f}")

            # æ··æ·†çŸ©é˜µ
            cm = confusion_matrix(true_labels_hq, hq_labels)

            fig = px.imshow(
                cm,
                text_auto=True,
                aspect="auto",
                title="æ··æ·†çŸ©é˜µ",
                labels=dict(x="é¢„æµ‹æ ‡ç­¾", y="çœŸå®æ ‡ç­¾"),
                x=['æ­£å¸¸', 'æ¬ºè¯ˆ'],
                y=['æ­£å¸¸', 'æ¬ºè¯ˆ']
            )

            st.plotly_chart(fig, use_container_width=True)


def _show_label_export():
    """æ˜¾ç¤ºæ ‡ç­¾å¯¼å‡º"""
    st.markdown("### ğŸ“¥ æ ‡ç­¾å¯¼å‡ºä¸åº”ç”¨")

    label_results = st.session_state.pseudo_labels
    engineered_data = st.session_state.engineered_features

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("**å¯¼å‡ºé€‰é¡¹**")

        export_option = st.radio(
            "é€‰æ‹©å¯¼å‡ºå†…å®¹",
            ["ä»…é«˜è´¨é‡æ ‡ç­¾", "å…¨éƒ¨æ ‡ç­¾", "æ ‡ç­¾å¯¹æ¯”æŠ¥å‘Š"]
        )

        include_features = st.checkbox("åŒ…å«ç‰¹å¾æ•°æ®", value=True)
        include_confidence = st.checkbox("åŒ…å«ç½®ä¿¡åº¦", value=True)

    with col2:
        st.markdown("**å¯¼å‡ºç»Ÿè®¡**")

        if export_option == "ä»…é«˜è´¨é‡æ ‡ç­¾":
            export_count = len(label_results.get('high_quality_labels', []))
            st.write(f"å¯¼å‡ºæ ·æœ¬æ•°: {export_count:,}")
        elif export_option == "å…¨éƒ¨æ ‡ç­¾":
            export_count = len(label_results.get('all_labels', []))
            st.write(f"å¯¼å‡ºæ ·æœ¬æ•°: {export_count:,}")
        else:
            export_count = len(label_results.get('all_labels', []))
            st.write(f"æŠ¥å‘Šæ ·æœ¬æ•°: {export_count:,}")

    # ç”Ÿæˆå¯¼å‡ºæ•°æ®
    if st.button("ğŸ“¥ ç”Ÿæˆå¯¼å‡ºæ–‡ä»¶", type="secondary"):
        try:
            if export_option == "ä»…é«˜è´¨é‡æ ‡ç­¾":
                export_data = _prepare_high_quality_export(label_results, engineered_data, include_features, include_confidence)
                filename = f"high_quality_pseudo_labels_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
            elif export_option == "å…¨éƒ¨æ ‡ç­¾":
                export_data = _prepare_all_labels_export(label_results, engineered_data, include_features, include_confidence)
                filename = f"all_pseudo_labels_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"
            else:
                export_data = _prepare_comparison_report(label_results, engineered_data)
                filename = f"pseudo_labels_report_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.csv"

            csv_data = export_data.to_csv(index=False)

            st.download_button(
                label=f"ğŸ“¥ ä¸‹è½½ {filename}",
                data=csv_data,
                file_name=filename,
                mime="text/csv"
            )

            st.success(f"âœ… å¯¼å‡ºæ–‡ä»¶å·²å‡†å¤‡å®Œæˆï¼ŒåŒ…å« {len(export_data)} æ¡è®°å½•")

        except Exception as e:
            st.error(f"âŒ å¯¼å‡ºå¤±è´¥: {str(e)}")

    # ä¸‹ä¸€æ­¥æŒ‰é’®
    st.markdown("---")
    col1, col2, col3 = st.columns([1, 1, 1])

    with col2:
        if st.button("ğŸ¤– ä¸‹ä¸€æ­¥ï¼šæ¨¡å‹è®­ç»ƒ", type="primary", use_container_width=True):
            st.success("âœ… é«˜è´¨é‡ä¼ªæ ‡ç­¾ç”Ÿæˆå®Œæˆï¼Œå¯ä»¥è¿›å…¥æ¨¡å‹è®­ç»ƒé¡µé¢ï¼")
            st.info("ğŸ’¡ è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©'ğŸ¤– æ¨¡å‹è®­ç»ƒ'é¡µé¢ç»§ç»­")


def _prepare_high_quality_export(label_results, engineered_data, include_features, include_confidence):
    """å‡†å¤‡é«˜è´¨é‡æ ‡ç­¾å¯¼å‡ºæ•°æ®"""
    hq_indices = label_results.get('high_quality_indices', [])
    hq_labels = label_results.get('high_quality_labels', [])
    hq_confidences = label_results.get('high_quality_confidences', [])

    # åŸºç¡€æ•°æ®
    export_data = pd.DataFrame({
        'sample_index': hq_indices,
        'pseudo_label': hq_labels
    })

    if include_confidence:
        export_data['confidence'] = hq_confidences

    if include_features:
        # æ·»åŠ ç‰¹å¾æ•°æ®
        feature_data = engineered_data.iloc[hq_indices].reset_index(drop=True)
        export_data = pd.concat([export_data, feature_data], axis=1)

    return export_data


def _prepare_all_labels_export(label_results, engineered_data, include_features, include_confidence):
    """å‡†å¤‡å…¨éƒ¨æ ‡ç­¾å¯¼å‡ºæ•°æ®"""
    all_labels = label_results.get('all_labels', [])
    all_confidences = label_results.get('all_confidences', [])

    # åŸºç¡€æ•°æ®
    export_data = pd.DataFrame({
        'sample_index': range(len(all_labels)),
        'pseudo_label': all_labels
    })

    if include_confidence:
        export_data['confidence'] = all_confidences

    # æ ‡è®°é«˜è´¨é‡æ ‡ç­¾
    hq_indices = set(label_results.get('high_quality_indices', []))
    export_data['is_high_quality'] = export_data['sample_index'].isin(hq_indices)

    if include_features:
        # æ·»åŠ ç‰¹å¾æ•°æ®
        export_data = pd.concat([export_data, engineered_data.reset_index(drop=True)], axis=1)

    return export_data


def _prepare_comparison_report(label_results, engineered_data):
    """å‡†å¤‡å¯¹æ¯”æŠ¥å‘Š"""
    all_labels = label_results.get('all_labels', [])
    all_confidences = label_results.get('all_confidences', [])
    hq_indices = set(label_results.get('high_quality_indices', []))

    # åŸºç¡€æŠ¥å‘Šæ•°æ®
    report_data = pd.DataFrame({
        'sample_index': range(len(all_labels)),
        'pseudo_label': all_labels,
        'confidence': all_confidences,
        'is_high_quality': [i in hq_indices for i in range(len(all_labels))]
    })

    # æ·»åŠ å…³é”®ç‰¹å¾
    key_features = ['transaction_id', 'customer_id', 'transaction_amount', 'customer_age', 'account_age_days']
    available_features = [f for f in key_features if f in engineered_data.columns]

    if available_features:
        report_data = pd.concat([
            report_data,
            engineered_data[available_features].reset_index(drop=True)
        ], axis=1)

    # æ·»åŠ çœŸå®æ ‡ç­¾å¯¹æ¯”ï¼ˆå¦‚æœæœ‰ï¼‰
    if 'is_fraudulent' in engineered_data.columns:
        report_data['true_label'] = engineered_data['is_fraudulent'].reset_index(drop=True)
        report_data['label_match'] = report_data['pseudo_label'] == report_data['true_label']

    return report_data
