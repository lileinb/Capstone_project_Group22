"""
èšç±»åˆ†æé¡µé¢
è´Ÿè´£ç”¨æˆ·è¡Œä¸ºæ¨¡å¼èšç±»å’Œå¼‚å¸¸ç¾¤ä½“è¯†åˆ«
"""

import streamlit as st
import pandas as pd
import numpy as np
import sys
import os
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

# å¯¼å…¥åç«¯æ¨¡å—
from backend.clustering.cluster_analyzer import ClusterAnalyzer
from backend.clustering.cluster_interpreter import ClusterInterpreter

def show():
    """æ˜¾ç¤ºèšç±»åˆ†æé¡µé¢"""
    st.markdown('<div class="sub-header">ğŸ“Š èšç±»åˆ†æä¸å¼‚å¸¸ç¾¤ä½“è¯†åˆ«</div>', unsafe_allow_html=True)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç‰¹å¾å·¥ç¨‹æ•°æ®
    if 'engineered_features' not in st.session_state or st.session_state.engineered_features is None:
        st.warning("âš ï¸ è¯·å…ˆå®Œæˆç‰¹å¾å·¥ç¨‹ï¼")
        st.info("ğŸ’¡ è¯·åœ¨'ğŸ”§ ç‰¹å¾å·¥ç¨‹'é¡µé¢å®Œæˆç‰¹å¾ç”Ÿæˆ")
        return
    
    # åˆå§‹åŒ–session state
    if 'clustering_results' not in st.session_state:
        st.session_state.clustering_results = None
    if 'cluster_labels' not in st.session_state:
        st.session_state.cluster_labels = None
    if 'cluster_analysis' not in st.session_state:
        st.session_state.cluster_analysis = None
    
    # è·å–ç‰¹å¾å·¥ç¨‹æ•°æ®
    engineered_data = st.session_state.engineered_features
    
    st.markdown("### ğŸ“Š æ•°æ®æ¦‚è§ˆ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("è®°å½•æ•°", f"{len(engineered_data):,}")
    
    with col2:
        st.metric("ç‰¹å¾æ•°", f"{len(engineered_data.columns)}")
    
    with col3:
        numeric_features = len(engineered_data.select_dtypes(include=['number']).columns)
        st.metric("æ•°å€¼ç‰¹å¾", f"{numeric_features}")
    
    with col4:
        if 'is_fraudulent' in engineered_data.columns:
            fraud_rate = (engineered_data['is_fraudulent'].sum() / len(engineered_data) * 100).round(2)
            st.metric("æ¬ºè¯ˆç‡", f"{fraud_rate}%")
        else:
            st.metric("æ¬ºè¯ˆç‡", "N/A")
    
    # èšç±»åˆ†æåŒºåŸŸ
    st.markdown("### ğŸ” èšç±»åˆ†æé…ç½®")
    
    st.markdown("""
    **èšç±»ç®—æ³•è¯´æ˜ï¼š**
    - **K-meansèšç±»**: åŸºäºè·ç¦»çš„ç¡¬èšç±»ï¼Œé€‚åˆå‘ç°çƒå½¢èšç±»
    - **DBSCANèšç±»**: åŸºäºå¯†åº¦çš„èšç±»ï¼Œé€‚åˆå‘ç°ä¸è§„åˆ™å½¢çŠ¶çš„èšç±»
    - **é«˜æ–¯æ··åˆæ¨¡å‹**: æ¦‚ç‡èšç±»æ–¹æ³•ï¼Œæä¾›è½¯èšç±»ç»“æœ
    """)
    
    # æ™ºèƒ½èšç±»é€‰é¡¹
    st.markdown("### ğŸ¤– æ™ºèƒ½èšç±»æ¨¡å¼")

    # æ·»åŠ æ™ºèƒ½èšç±»é€‰æ‹©
    clustering_mode = st.radio(
        "é€‰æ‹©èšç±»æ¨¡å¼",
        ["ğŸ¤– æ™ºèƒ½è‡ªåŠ¨èšç±» (æ¨è)", "âš™ï¸ æ‰‹åŠ¨å‚æ•°è°ƒæ•´"],
        help="æ™ºèƒ½æ¨¡å¼ä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜ç‰¹å¾ã€ç®—æ³•å’Œå‚æ•°ï¼Œæ‰‹åŠ¨æ¨¡å¼å…è®¸è‡ªå®šä¹‰é…ç½®"
    )

    if clustering_mode == "ğŸ¤– æ™ºèƒ½è‡ªåŠ¨èšç±» (æ¨è)":
        st.info("""
        ğŸ¯ **æ™ºèƒ½èšç±»æ¨¡å¼ç‰¹ç‚¹**:
        - ğŸ” è‡ªåŠ¨ç‰¹å¾é€‰æ‹©å’Œå·¥ç¨‹
        - âš™ï¸ è‡ªåŠ¨ç®—æ³•å’Œå‚æ•°ä¼˜åŒ–
        - ğŸ“Š è‡ªåŠ¨é£é™©é˜ˆå€¼è°ƒæ•´
        - ğŸ¯ ç¡®ä¿å››å±‚é£é™©åˆ†å¸ƒ
        - ğŸ“ˆ æœ€å¤§åŒ–èšç±»è´¨é‡æŒ‡æ ‡
        """)

        # ç›®æ ‡é£é™©åˆ†å¸ƒè®¾ç½®
        st.markdown("#### ğŸ¯ ç›®æ ‡é£é™©åˆ†å¸ƒ")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            target_low = st.slider("ä½é£é™©æ¯”ä¾‹", 0.2, 0.8, 0.5, 0.05, help="ç›®æ ‡ä½é£é™©ç”¨æˆ·æ¯”ä¾‹")
        with col2:
            target_medium = st.slider("ä¸­é£é™©æ¯”ä¾‹", 0.1, 0.5, 0.3, 0.05, help="ç›®æ ‡ä¸­é£é™©ç”¨æˆ·æ¯”ä¾‹")
        with col3:
            target_high = st.slider("é«˜é£é™©æ¯”ä¾‹", 0.05, 0.4, 0.15, 0.05, help="ç›®æ ‡é«˜é£é™©ç”¨æˆ·æ¯”ä¾‹")
        with col4:
            target_critical = st.slider("æé«˜é£é™©æ¯”ä¾‹", 0.01, 0.2, 0.05, 0.01, help="ç›®æ ‡æé«˜é£é™©ç”¨æˆ·æ¯”ä¾‹")

        # ç¡®ä¿æ¯”ä¾‹æ€»å’Œä¸º1
        total = target_low + target_medium + target_high + target_critical
        if abs(total - 1.0) > 0.01:
            st.warning(f"âš ï¸ é£é™©æ¯”ä¾‹æ€»å’Œåº”ä¸º100%ï¼Œå½“å‰ä¸º{total*100:.1f}%")

        target_risk_distribution = {
            'low': target_low,
            'medium': target_medium,
            'high': target_high,
            'critical': target_critical
        }

        # æ™ºèƒ½èšç±»æŒ‰é’®
        if st.button("ğŸš€ å¼€å§‹æ™ºèƒ½èšç±»", type="primary", help="ä¸€é”®æ‰§è¡Œæœ€ä¼˜èšç±»åˆ†æ"):
            with st.spinner("ğŸ”„ æ­£åœ¨æ‰§è¡Œæ™ºèƒ½èšç±»ä¼˜åŒ–..."):
                try:
                    analyzer = ClusterAnalyzer()
                    result = analyzer.intelligent_auto_clustering(
                        engineered_data, target_risk_distribution
                    )

                    # å­˜å‚¨æ™ºèƒ½èšç±»ç»“æœ
                    st.session_state.clustering_result = result

                    # åŒæ—¶ä»¥æ ‡å‡†æ ¼å¼å­˜å‚¨ï¼Œä¾›å…¶ä»–æ¨¡å—ä½¿ç”¨
                    standard_clustering_results = {
                        'algorithm': result.get('algorithm', 'kmeans'),
                        'n_clusters': result.get('n_clusters', 3),
                        'cluster_count': result.get('n_clusters', 3),
                        'cluster_details': result.get('cluster_details', []),
                        'cluster_labels': result.get('cluster_labels', []),
                        'silhouette_score': result.get('silhouette_score', 0),
                        'calinski_harabasz_score': result.get('calinski_harabasz_score', 0),
                        'selected_features': result.get('selected_features', []),
                        'optimal_thresholds': result.get('optimal_thresholds', {}),
                        'risk_mapping': result.get('risk_mapping', {}),
                        'optimization_summary': result.get('optimization_summary', {}),
                        'source': 'intelligent_clustering'
                    }

                    st.session_state.clustering_results = standard_clustering_results
                    st.session_state.cluster_labels = result.get('cluster_labels', [])
                    st.session_state.cluster_analysis = {
                        'algorithm': result.get('algorithm', 'kmeans'),
                        'features': result.get('selected_features', []),
                        'n_clusters': result.get('n_clusters', 3),
                        'cluster_sizes': {},
                        'source': 'intelligent_clustering'
                    }

                    st.success("âœ… æ™ºèƒ½èšç±»å®Œæˆï¼")
                    st.rerun()

                except Exception as e:
                    st.error(f"âŒ æ™ºèƒ½èšç±»å¤±è´¥: {e}")

        # å¦‚æœæœ‰æ™ºèƒ½èšç±»ç»“æœï¼Œæ˜¾ç¤ºä¼˜åŒ–æ‘˜è¦
        if ('clustering_result' in st.session_state and
            st.session_state.clustering_result is not None and
            'optimization_summary' in st.session_state.clustering_result):
            result = st.session_state.clustering_result
            summary = result['optimization_summary']

            st.markdown("### ğŸ“Š æ™ºèƒ½ä¼˜åŒ–æ‘˜è¦")

            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("è½®å»“ç³»æ•°", f"{summary['silhouette_score']:.3f}")
            with col2:
                st.metric("èšç±»æ•°é‡", summary['n_clusters'])
            with col3:
                st.metric("é€‰æ‹©ç‰¹å¾æ•°", summary['feature_count'])
            with col4:
                st.metric("ç®—æ³•", summary['algorithm'].upper())

            # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
            if 'recommendations' in result:
                st.markdown("#### ğŸ’¡ ä¼˜åŒ–å»ºè®®")
                for rec in result['recommendations']:
                    st.write(f"- {rec}")

            # æ˜¾ç¤ºé€‰æ‹©çš„ç‰¹å¾
            if 'selected_features' in result:
                st.markdown("#### ğŸ¯ è‡ªåŠ¨é€‰æ‹©çš„ç‰¹å¾")
                st.write(", ".join(result['selected_features']))

            # æ˜¾ç¤ºä¼˜åŒ–åçš„é˜ˆå€¼
            if 'optimal_thresholds' in result:
                st.markdown("#### âš™ï¸ ä¼˜åŒ–åçš„é£é™©é˜ˆå€¼")
                thresholds = result['optimal_thresholds']
                st.write(f"ä½é£é™©: <{thresholds['low']}, ä¸­é£é™©: {thresholds['low']}-{thresholds['medium']}, "
                        f"é«˜é£é™©: {thresholds['medium']}-{thresholds['high']}, æé«˜é£é™©: >{thresholds['high']}")

        return  # æ™ºèƒ½æ¨¡å¼ä¸‹ä¸éœ€è¦æ‰‹åŠ¨å‚æ•°è®¾ç½®

    # æ‰‹åŠ¨å‚æ•°è°ƒæ•´æ¨¡å¼
    st.markdown("### âš™ï¸ æ‰‹åŠ¨å‚æ•°è°ƒæ•´")

    # èšç±»å‚æ•°è®¾ç½®
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### âš™ï¸ èšç±»ç®—æ³•é€‰æ‹©")

        # ç®—æ³•é€‰æ‹©
        algorithm = st.selectbox(
            "é€‰æ‹©èšç±»ç®—æ³•",
            ["K-means", "DBSCAN", "Gaussian Mixture"],
            help="é€‰æ‹©é€‚åˆæ•°æ®ç‰¹ç‚¹çš„èšç±»ç®—æ³•"
        )
        
        # ç‰¹å¾é€‰æ‹©
        numeric_cols = engineered_data.select_dtypes(include=['number']).columns.tolist()
        if 'is_fraudulent' in numeric_cols:
            numeric_cols.remove('is_fraudulent')  # æ’é™¤æ ‡ç­¾åˆ—
        
        selected_features = st.multiselect(
            "é€‰æ‹©èšç±»ç‰¹å¾",
            numeric_cols,
            default=numeric_cols[:min(10, len(numeric_cols))],
            help="é€‰æ‹©ç”¨äºèšç±»çš„æ•°å€¼ç‰¹å¾"
        )
    
    with col2:
        st.markdown("#### ğŸ“Š ç®—æ³•å‚æ•°")
        
        # é»˜è®¤å‚æ•°
        n_clusters = 5
        random_state = 42

        if algorithm == "K-means":
            n_clusters = st.slider("èšç±»æ•°é‡", 2, 10, 5, help="K-meansèšç±»æ•°é‡")
            max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 100, 1000, 300, help="æœ€å¤§è¿­ä»£æ¬¡æ•°")
            random_state = st.slider("éšæœºç§å­", 0, 100, 42, help="éšæœºç§å­")

        elif algorithm == "DBSCAN":
            eps = st.slider("é‚»åŸŸåŠå¾„", 0.1, 2.0, 0.5, 0.1, help="DBSCANé‚»åŸŸåŠå¾„")
            min_samples = st.slider("æœ€å°æ ·æœ¬æ•°", 2, 20, 5, help="å½¢æˆæ ¸å¿ƒç‚¹æ‰€éœ€çš„æœ€å°æ ·æœ¬æ•°")
            n_clusters = 5  # DBSCANä¸éœ€è¦é¢„è®¾èšç±»æ•°ï¼Œä½†ClusterAnalyzeréœ€è¦è¿™ä¸ªå‚æ•°

        elif algorithm == "Gaussian Mixture":
            n_clusters = st.slider("æ··åˆæˆåˆ†æ•°", 2, 10, 5, help="é«˜æ–¯æ··åˆæˆåˆ†æ•°é‡")
            max_iter = st.slider("æœ€å¤§è¿­ä»£æ¬¡æ•°", 100, 1000, 300, help="æœ€å¤§è¿­ä»£æ¬¡æ•°")
            random_state = st.slider("éšæœºç§å­", 0, 100, 42, help="éšæœºç§å­")
    
    # æ‰§è¡Œèšç±»åˆ†æ
    col1, col2 = st.columns([3, 1])

    with col1:
        run_clustering = st.button("ğŸš€ æ‰§è¡Œèšç±»åˆ†æ", type="primary", help="åŸºäºå½“å‰å‚æ•°è¿›è¡Œèšç±»åˆ†æ")

    with col2:
        clear_cache = st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜", help="æ¸…é™¤ä¹‹å‰çš„èšç±»ç»“æœ")

    if clear_cache:
        # æ¸…é™¤session stateä¸­çš„èšç±»ç›¸å…³æ•°æ®
        keys_to_clear = ['clustering_results', 'cluster_labels', 'clustering_analysis', 'cluster_analysis']
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]
        st.success("âœ… ç¼“å­˜å·²æ¸…é™¤ï¼")
        st.rerun()

    if run_clustering:
        try:
            with st.spinner("æ­£åœ¨è¿›è¡Œèšç±»åˆ†æ..."):
                # å‡†å¤‡æ•°æ®
                clustering_data = engineered_data[selected_features].copy()
                
                # æ•°æ®æ ‡å‡†åŒ–
                from sklearn.preprocessing import StandardScaler
                scaler = StandardScaler()
                clustering_data_scaled = scaler.fit_transform(clustering_data)
                
                # åˆ›å»ºèšç±»åˆ†æå™¨
                cluster_analyzer = ClusterAnalyzer(n_clusters=n_clusters, random_state=random_state)

                # æ‰§è¡Œèšç±»ï¼ˆä½¿ç”¨æ–°çš„APIï¼‰
                algorithm_map = {
                    "K-means": "kmeans",
                    "DBSCAN": "dbscan",
                    "Gaussian Mixture": "gaussian_mixture"
                }

                clustering_results = cluster_analyzer.analyze_clusters(
                    engineered_data,
                    algorithm=algorithm_map.get(algorithm, "kmeans")
                )

                # æå–èšç±»æ ‡ç­¾
                cluster_labels = clustering_results.get('cluster_labels', [])
                
                # ä¿å­˜èšç±»ç»“æœ
                st.session_state.cluster_labels = cluster_labels
                st.session_state.clustering_results = clustering_results
                st.session_state.clustering_analysis = {
                    'algorithm': algorithm,
                    'features': selected_features,
                    'n_clusters': len(np.unique(cluster_labels)),
                    'cluster_sizes': pd.Series(cluster_labels).value_counts().to_dict()
                }
                
                # èšç±»è§£é‡Š
                cluster_interpreter = ClusterInterpreter()
                cluster_analysis = cluster_interpreter.analyze_clusters(
                    engineered_data, cluster_labels, selected_features
                )
                st.session_state.cluster_analysis = cluster_analysis
                
                st.success("âœ… èšç±»åˆ†æå®Œæˆï¼")

                # è°ƒè¯•ä¿¡æ¯
                with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯", expanded=False):
                    st.write("èšç±»ç»“æœé”®:", list(clustering_results.keys()))
                    st.write("èšç±»æ•°é‡:", clustering_results.get('cluster_count', 0))

                    cluster_details = clustering_results.get('cluster_details', [])
                    st.write("èšç±»è¯¦æƒ…æ•°é‡:", len(cluster_details))

                    for i, detail in enumerate(cluster_details):
                        st.write(f"èšç±» {i}:")
                        st.write(f"  - å¤§å°: {detail.get('size', 0)}")
                        st.write(f"  - æ¬ºè¯ˆç‡: {detail.get('fraud_rate', 0):.4f}")
                        st.write(f"  - é£é™©ç­‰çº§: {detail.get('risk_level', 'unknown')}")
                
        except Exception as e:
            st.error(f"âŒ èšç±»åˆ†æå¤±è´¥: {e}")
            st.exception(e)
    
    # æ˜¾ç¤ºèšç±»ç»“æœ
    if st.session_state.clustering_results is not None:
        st.markdown("### ğŸ“ˆ èšç±»åˆ†æç»“æœ")
        
        clustering_results = st.session_state.clustering_results
        cluster_labels = st.session_state.cluster_labels
        cluster_analysis = st.session_state.cluster_analysis
        
        # èšç±»ç»Ÿè®¡
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ç®—æ³•", clustering_results['algorithm'])
        
        with col2:
            st.metric("èšç±»æ•°é‡", clustering_results.get('cluster_count', 0))
        
        with col3:
            st.metric("ç‰¹å¾æ•°é‡", len(selected_features))
        
        with col4:
            total_records = len(cluster_labels)
            st.metric("æ€»è®°å½•æ•°", f"{total_records:,}")
        
        # èšç±»åˆ†å¸ƒ
        st.markdown("#### ğŸ“Š èšç±»åˆ†å¸ƒ")
        
        cluster_sizes = pd.Series(cluster_labels).value_counts().sort_index()
        
        # èšç±»å¤§å°åˆ†å¸ƒå›¾
        fig = px.bar(
            x=cluster_sizes.index,
            y=cluster_sizes.values,
            title="èšç±»å¤§å°åˆ†å¸ƒ",
            labels={'x': 'èšç±»æ ‡ç­¾', 'y': 'è®°å½•æ•°'}
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # èšç±»å¤§å°è¡¨æ ¼
        cluster_df = pd.DataFrame({
            'èšç±»æ ‡ç­¾': cluster_sizes.index,
            'è®°å½•æ•°': cluster_sizes.values,
            'å æ¯”(%)': (cluster_sizes.values / total_records * 100).round(2)
        })
        st.dataframe(cluster_df, use_container_width=True)
        
        # èšç±»ç‰¹å¾åˆ†æ
        if clustering_results and 'cluster_details' in clustering_results:
            st.markdown("#### ğŸ” èšç±»ç‰¹å¾åˆ†æ")

            cluster_details = clustering_results['cluster_details']

            # èšç±»è¯¦æƒ…è¡¨æ ¼
            if cluster_details:
                st.markdown("**èšç±»è¯¦æƒ…**")

                details_data = []
                for detail in cluster_details:
                    details_data.append({
                        'èšç±»ID': detail.get('cluster_id', 'N/A'),
                        'å¤§å°': detail.get('size', 0),
                        'å æ¯”(%)': detail.get('percentage', 0),
                        'å¹³å‡äº¤æ˜“é‡‘é¢': detail.get('avg_transaction_amount', 0),
                        'å¹³å‡å®¢æˆ·å¹´é¾„': detail.get('avg_customer_age', 0),
                        'å¸¸è§æ”¯ä»˜æ–¹å¼': detail.get('common_payment_method', 'unknown'),
                        'å¸¸è§è®¾å¤‡': detail.get('common_device', 'unknown'),
                        'æ¬ºè¯ˆç‡': detail.get('fraud_rate', 0),
                        'é£é™©ç­‰çº§': detail.get('risk_level', 'low')
                    })

                details_df = pd.DataFrame(details_data)
                st.dataframe(details_df, use_container_width=True)

                # èšç±»é£é™©ç­‰çº§åˆ†å¸ƒ - ä¿®å¤ï¼šä½¿ç”¨é£é™©æ˜ å°„å™¨çš„ç»“æœ
                # ä¼˜å…ˆä½¿ç”¨é£é™©æ˜ å°„å™¨çš„ç»“æœï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨cluster_detailsä¸­çš„é£é™©ç­‰çº§
                cluster_risk_mapping = clustering_results.get('cluster_risk_mapping', {})

                if cluster_risk_mapping:
                    # ä½¿ç”¨é£é™©æ˜ å°„å™¨çš„ç»“æœ
                    risk_levels = []
                    for detail in cluster_details:
                        cluster_id = detail.get('cluster_id', -1)
                        if cluster_id in cluster_risk_mapping:
                            risk_level = cluster_risk_mapping[cluster_id].get('risk_level', 'low')
                        else:
                            risk_level = detail.get('risk_level', 'low')
                        risk_levels.append(risk_level)
                else:
                    # å›é€€åˆ°cluster_detailsä¸­çš„é£é™©ç­‰çº§
                    risk_levels = [detail.get('risk_level', 'low') for detail in cluster_details]

                risk_counts = pd.Series(risk_levels).value_counts()

                if len(risk_counts) > 0:
                    # å®šä¹‰é£é™©ç­‰çº§é¢œè‰²
                    risk_colors = {
                        'low': '#22c55e',      # ç»¿è‰²
                        'medium': '#f59e0b',   # é»„è‰²
                        'high': '#f97316',     # æ©™è‰²
                        'critical': '#ef4444'  # çº¢è‰²
                    }

                    fig = px.pie(
                        values=risk_counts.values,
                        names=risk_counts.index,
                        title="èšç±»é£é™©ç­‰çº§åˆ†å¸ƒ",
                        color=risk_counts.index,
                        color_discrete_map=risk_colors
                    )
                    st.plotly_chart(fig, use_container_width=True)

                    # æ˜¾ç¤ºé£é™©åˆ†å¸ƒç»Ÿè®¡
                    st.markdown("**é£é™©åˆ†å¸ƒç»Ÿè®¡:**")
                    for level, count in risk_counts.items():
                        percentage = count / len(risk_levels) * 100
                        st.markdown(f"- {level.title()}: {count} ä¸ªèšç±» ({percentage:.1f}%)")
            
        # èšç±»è´¨é‡è¯„ä¼°
        if clustering_results and 'quality_metrics' in clustering_results:
            st.markdown("#### ğŸ“Š èšç±»è´¨é‡è¯„ä¼°")

            quality_metrics = clustering_results['quality_metrics']

            col1, col2 = st.columns(2)

            with col1:
                silhouette_score = quality_metrics.get('silhouette_score', 0)
                st.metric(
                    "è½®å»“ç³»æ•° (Silhouette Score)",
                    f"{silhouette_score:.3f}",
                    help="èŒƒå›´[-1,1]ï¼Œè¶Šæ¥è¿‘1è¡¨ç¤ºèšç±»æ•ˆæœè¶Šå¥½"
                )

            with col2:
                calinski_score = quality_metrics.get('calinski_harabasz_score', 0)
                st.metric(
                    "Calinski-HarabaszæŒ‡æ•°",
                    f"{calinski_score:.1f}",
                    help="å€¼è¶Šå¤§è¡¨ç¤ºèšç±»æ•ˆæœè¶Šå¥½"
                )
        
        # èšç±»å¯è§†åŒ–
        st.markdown("#### ğŸ¨ èšç±»å¯è§†åŒ–")
        
        # é€‰æ‹©å¯è§†åŒ–ç‰¹å¾
        if len(selected_features) >= 2:
            col1, col2 = st.columns(2)
            
            with col1:
                x_feature = st.selectbox("Xè½´ç‰¹å¾", selected_features, index=0)
            
            with col2:
                y_feature = st.selectbox("Yè½´ç‰¹å¾", selected_features, index=1)
            
            # åˆ›å»ºæ•£ç‚¹å›¾
            plot_data = pd.DataFrame({
                'x': engineered_data[x_feature],
                'y': engineered_data[y_feature],
                'cluster': cluster_labels
            })
            
            fig = px.scatter(
                plot_data,
                x='x',
                y='y',
                color='cluster',
                title=f"èšç±»ç»“æœæ•£ç‚¹å›¾ ({x_feature} vs {y_feature})",
                labels={'x': x_feature, 'y': y_feature}
            )
            st.plotly_chart(fig, use_container_width=True)
        
        # å¼‚å¸¸èšç±»è¯†åˆ«
        st.markdown("#### âš ï¸ å¼‚å¸¸èšç±»è¯†åˆ«")

        if clustering_results and 'anomaly_analysis' in clustering_results:
            anomaly_analysis = clustering_results['anomaly_analysis']

            # é«˜é£é™©èšç±»
            high_risk_clusters = anomaly_analysis.get('high_risk_clusters', [])
            if high_risk_clusters:
                st.warning(f"å‘ç° {len(high_risk_clusters)} ä¸ªé«˜é£é™©èšç±»")

                for cluster_info in high_risk_clusters:
                    with st.expander(f"é«˜é£é™©èšç±» {cluster_info['cluster_id']}"):
                        st.markdown(f"**æ¬ºè¯ˆç‡**: {cluster_info['fraud_rate']:.3f}")
                        st.markdown(f"**èšç±»å¤§å°**: {cluster_info['size']} æ¡è®°å½•")

            # å°èšç±»
            small_clusters = anomaly_analysis.get('small_clusters', [])
            if small_clusters:
                st.info(f"å‘ç° {len(small_clusters)} ä¸ªå°èšç±»ï¼ˆå¯èƒ½çš„å¼‚å¸¸æ¨¡å¼ï¼‰")

                for cluster_info in small_clusters:
                    with st.expander(f"å°èšç±» {cluster_info['cluster_id']}"):
                        st.markdown(f"**èšç±»å¤§å°**: {cluster_info['size']} æ¡è®°å½•")
                        st.markdown(f"**å æ¯”**: {cluster_info['percentage']:.2f}%")

            if not high_risk_clusters and not small_clusters:
                st.success("âœ… æœªå‘ç°æ˜æ˜¾å¼‚å¸¸èšç±»")
        
        # èšç±»ä¸æ¬ºè¯ˆå…³ç³»åˆ†æ
        if 'is_fraudulent' in engineered_data.columns:
            st.markdown("#### ğŸ¯ èšç±»ä¸æ¬ºè¯ˆå…³ç³»åˆ†æ")
            
            # è®¡ç®—æ¯ä¸ªèšç±»çš„æ¬ºè¯ˆç‡
            fraud_by_cluster = engineered_data.groupby(cluster_labels)['is_fraudulent'].agg(['count', 'sum', 'mean'])
            fraud_by_cluster.columns = ['æ€»è®°å½•æ•°', 'æ¬ºè¯ˆè®°å½•æ•°', 'æ¬ºè¯ˆç‡']
            fraud_by_cluster['æ¬ºè¯ˆç‡(%)'] = (fraud_by_cluster['æ¬ºè¯ˆç‡'] * 100).round(2)
            
            # æ¬ºè¯ˆç‡åˆ†å¸ƒå›¾
            fig = px.bar(
                x=fraud_by_cluster.index,
                y=fraud_by_cluster['æ¬ºè¯ˆç‡(%)'],
                title="å„èšç±»æ¬ºè¯ˆç‡åˆ†å¸ƒ",
                labels={'x': 'èšç±»æ ‡ç­¾', 'y': 'æ¬ºè¯ˆç‡(%)'}
            )
            st.plotly_chart(fig, use_container_width=True)
            
            # æ¬ºè¯ˆç‡è¡¨æ ¼
            st.dataframe(fraud_by_cluster, use_container_width=True)
        
        # æ•°æ®é¢„è§ˆ
        st.markdown("#### ğŸ“‹ èšç±»ç»“æœé¢„è§ˆ")
        
        # æ·»åŠ èšç±»æ ‡ç­¾åˆ°æ•°æ®
        result_data = engineered_data.copy()
        result_data['cluster_label'] = cluster_labels
        
        st.dataframe(result_data.head(10), use_container_width=True)
        
        # ä¸‹ä¸€æ­¥æŒ‰é’®
        st.markdown("---")
        col1, col2, col3 = st.columns([1, 1, 1])
        
        with col2:
            if st.button("ğŸš€ è¿›å…¥é£é™©è¯„åˆ†", type="primary", use_container_width=True):
                st.success("âœ… èšç±»åˆ†æå®Œæˆï¼Œå¯ä»¥è¿›å…¥é£é™©è¯„åˆ†é¡µé¢ï¼")
                st.info("ğŸ’¡ è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©'ğŸ¯ é£é™©è¯„åˆ†'é¡µé¢ç»§ç»­")
    
    else:
        # æ˜¾ç¤ºèšç±»åˆ†æè¯´æ˜
        st.markdown("### ğŸ“ èšç±»åˆ†æè¯´æ˜")
        
        st.markdown("""
        **èšç±»ç®—æ³•ç‰¹ç‚¹ï¼š**
        
        1. **K-meansèšç±»**
           - åŸºäºæ¬§å‡ é‡Œå¾—è·ç¦»çš„ç¡¬èšç±»
           - é€‚åˆå‘ç°çƒå½¢æˆ–å‡¸å½¢èšç±»
           - è®¡ç®—é€Ÿåº¦å¿«ï¼Œç»“æœç¨³å®š
           - éœ€è¦é¢„å…ˆæŒ‡å®šèšç±»æ•°é‡
        
        2. **DBSCANèšç±»**
           - åŸºäºå¯†åº¦çš„èšç±»ç®—æ³•
           - èƒ½å‘ç°ä¸è§„åˆ™å½¢çŠ¶çš„èšç±»
           - è‡ªåŠ¨è¯†åˆ«å¼‚å¸¸ç‚¹
           - ä¸éœ€è¦é¢„å…ˆæŒ‡å®šèšç±»æ•°é‡
        
        3. **é«˜æ–¯æ··åˆæ¨¡å‹**
           - æ¦‚ç‡èšç±»æ–¹æ³•
           - æä¾›è½¯èšç±»ç»“æœ
           - èƒ½å¤„ç†é‡å èšç±»
           - é€‚åˆå¤æ‚çš„æ•°æ®åˆ†å¸ƒ
        
        **èšç±»åˆ†æç›®æ ‡ï¼š**
        - å‘ç°ç”¨æˆ·è¡Œä¸ºæ¨¡å¼
        - è¯†åˆ«å¼‚å¸¸ç¾¤ä½“
        - ä¸ºé£é™©è¯„åˆ†æä¾›ä¾æ®
        - æ”¯æŒä¸ªæ€§åŒ–é£é™©ç­–ç•¥
        """) 